+ run_with_logger --tag startup-script
+ local tag=dataproc-script
+ local pid=1253
+ [[ --tag == \-\-\t\a\g ]]
+ tag=dataproc-startup-script
+ shift 2
+ [[ 0 -eq 0 ]]
+ exec
++ logger -s -t 'dataproc-startup-script[1253]'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + cd /tmp
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + trap logstacktrace ERR
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + loginfo 'Starting Dataproc startup script'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + echo 'Starting Dataproc startup script'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: Starting Dataproc startup script
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_value cpu-platform
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + loginfo 'CPU platform: Intel Emerald Rapids'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + echo 'CPU platform: Intel Emerald Rapids'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: CPU platform: Intel Emerald Rapids
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + set -a
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_project_id
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_PROJECT_ID ../project/project-id
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + PROJECT=euphoric-coral-451717-v8
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_dataproc_region
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_REGION attributes/dataproc-region
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + REGION=us-east1
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_zone
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ local zone_uri
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_ZONE zone
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ zone_uri=projects/679657336577/zones/us-east1-d
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ echo us-east1-d
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + ZONE=us-east1-d
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_role
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + ROLE=Worker
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_bucket
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_BUCKET attributes/dataproc-bucket
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CONFIGBUCKET=dataproc-staging-us-east1-679657336577-kutp8kah
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_temp_bucket
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_TEMP_BUCKET attributes/dataproc-temp-bucket
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + TEMP_BUCKET=dataproc-temp-us-east1-679657336577-juievcnm
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_cluster_name
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_CLUSTER_NAME attributes/dataproc-cluster-name
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CLUSTER_NAME=cluster-dip-01
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_cluster_uuid
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_CLUSTER_UUID attributes/dataproc-cluster-uuid
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CLUSTER_UUID=0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_worker_count
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_WORKER_COUNT attributes/dataproc-worker-count
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + WORKER_COUNT=3
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_master
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_metadata_master_additional
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + MASTER_COUNT=1
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ hostname -s
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + MY_HOSTNAME=cluster-dip-01-w-2
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ hostname -f
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + MY_FULL_HOSTNAME=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ dnsdomainname
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + DOMAIN=c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + DATAPROC_MASTER_FQDN=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + KEYTAB_DIR=/etc/security/keytab
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CLUSTER_STAGING_FOLDER=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CLUSTER_TEMP_FOLDER=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + DATAPROC_ETC_DIR=/etc/google-dataproc
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + CLUSTER_PROPERTIES_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + UNINSTALL_TMP_DIR=/tmp/dataproc/uninstall
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + UNINSTALL_PRE_ACTIVATE_TMP_DIR=/tmp/dataproc/uninstall-pre-activate
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + COMPONENT_SERVICES=('hadoop-hdfs-namenode' 'hadoop-hdfs-datanode' 'hadoop-hdfs-zkfc' 'hadoop-hdfs-secondarynamenode' 'hadoop-hdfs-journalnode' 'hive-metastore' 'hive-server2' 'mysql-server' 'spark-history-server')
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + readonly COMPONENT_SERVICES
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard != \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + set +a
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + mkdir -p /tmp/dataproc /tmp/dataproc/commands /tmp/dataproc/components /tmp/dataproc/uninstall /tmp/dataproc/uninstall-pre-activate
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.3
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + merge_java_properties /tmp/cluster/properties/dataproc.properties /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r src=/tmp/cluster/properties/dataproc.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r dest=/etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/dataproc.properties ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + cat /tmp/cluster/properties/dataproc.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/dataproc.properties.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/dataproc.properties.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/dataproc.properties.
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + merge_java_properties /etc/google-dataproc/dataproc.custom.properties /etc/google-dataproc/dataproc.properties '\n# Custom image supplied properties'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r src=/etc/google-dataproc/dataproc.custom.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r dest=/etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local -r 'header=\n# Custom image supplied properties'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ ! -f /etc/google-dataproc/dataproc.custom.properties ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + loginfo 'Skipping merging /etc/google-dataproc/dataproc.custom.properties, file does not exist.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + echo 'Skipping merging /etc/google-dataproc/dataproc.custom.properties, file does not exist.'
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: Skipping merging /etc/google-dataproc/dataproc.custom.properties, file does not exist.
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + update_credentials_for_tpc
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: + local storage_api_endpoint
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ get_storage_api_endpoint
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: ++ local universe_domain
<13>Apr 27 18:07:21 dataproc-startup-script[1253]: +++ gcloud config get core/universe_domain
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ universe_domain=googleapis.com
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ [[ -n googleapis.com ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ echo storage.googleapis.com
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + storage_api_endpoint=storage.googleapis.com
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ storage.googleapis.com == \s\t\o\r\a\g\e\.\a\p\i\s\-\t\p\c\z\e\r\o\.\g\o\o\g ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + determine_selected_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -a default_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + default_components=($(get_default_components))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_default_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +o pipefail
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.components.default 'earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn stackdriver-agent-container google-fluentd-container pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE='knox proxy-agent'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_default_components earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn stackdriver-agent-container google-fluentd-container pig fluentbit-ucp otel-ucp miniconda3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + default_components=('earlyoom' 'hdfs' 'hive-metastore' 'hive-server2' 'mapreduce' 'mysql' 'npd' 'spark' 'tez' 'yarn' 'stackdriver-agent-container' 'google-fluentd-container' 'pig' 'fluentbit-ucp' 'otel-ucp' 'miniconda3')
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local default_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected earlyoom
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=earlyoom
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *earlyoom* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component earlyoom
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=earlyoom
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent == *earlyoom* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' earlyoom'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *hdfs* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom == *hdfs* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' hdfs'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected hive-metastore
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hive-metastore
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *hive-metastore* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component hive-metastore
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hive-metastore
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs == *hive-metastore* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' hive-metastore'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected hive-server2
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hive-server2
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *hive-server2* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component hive-server2
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hive-server2
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore == *hive-server2* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' hive-server2'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected mapreduce
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=mapreduce
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *mapreduce* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component mapreduce
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=mapreduce
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 == *mapreduce* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' mapreduce'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected mysql
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=mysql
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *mysql* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component mysql
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=mysql
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce == *mysql* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' mysql'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected npd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=npd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *npd* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component npd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=npd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql == *npd* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' npd'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected spark
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=spark
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *spark* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component spark
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=spark
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd == *spark* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' spark'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected tez
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=tez
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *tez* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component tez
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=tez
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark == *tez* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' tez'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected yarn
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=yarn
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *yarn* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component yarn
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=yarn
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez == *yarn* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' yarn'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected stackdriver-agent-container
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=stackdriver-agent-container
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *stackdriver-agent-container* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected google-fluentd-container
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=google-fluentd-container
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *google-fluentd-container* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected pig
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=pig
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *pig* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component pig
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=pig
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn == *pig* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' pig'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected fluentbit-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=fluentbit-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *fluentbit-ucp* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component fluentbit-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=fluentbit-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig == *fluentbit-ucp* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' fluentbit-ucp'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected otel-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=otel-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *otel-ucp* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component otel-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=otel-ucp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp == *otel-ucp* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' otel-ucp'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for component in "${default_components[@]}"
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_explicitly_unselected miniconda3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=miniconda3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local deactivated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.deactivate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + deactivated_components='google-fluentd-container stackdriver-agent-container'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ google-fluentd-container stackdriver-agent-container == *miniconda3* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + add_optional_component miniconda3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=miniconda3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp == *miniconda3* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + OPTIONAL_COMPONENTS_VALUE+=' miniconda3'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + sed -i 's/dataproc.components.activate=.*/dataproc.components.activate=knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3/g' /etc/google-dataproc/dataproc.properties
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + (( 1 > 1 ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local caching_enabled
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.cluster.caching.enabled false
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + caching_enabled=false
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + SELECTED_COMPONENTS=(${OPTIONAL_COMPONENTS_VALUE})
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_selected kerberos
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=kerberos
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + HADOOP_CONF_DIR=/etc/hadoop/conf
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + HBASE_CONF_DIR=/etc/hbase/conf
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + SPARK_CONF_DIR=/etc/spark/conf
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + export_hcfs_root_uri
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_property_in_xml /tmp/cluster/properties/core.xml fs.defaultFS
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + HCFS_ROOT_URI=
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -z '' ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_component_selected hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r component=hdfs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *hdfs* ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + (( 1 > 1 ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + HCFS_ROOT_URI=hdfs://cluster-dip-01-m
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + readonly HCFS_ROOT_URI
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + export HCFS_ROOT_URI
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + SERVICES=()
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + ARTIFACTS_TO_UNINSTALL=(${DATAPROC_MASTER_SERVICES} ${DATAPROC_MASTER_EXCLUSIVE_SERVICES} ${DATAPROC_MASTER_STANDALONE_SERVICES} ${DATAPROC_MASTER_HA_SERVICES})
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + enable_worker_services
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for service in ${DATAPROC_WORKER_SERVICES}
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + in_array hadoop-hdfs-datanode DATAPROC_COMPONENTS
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r value=hadoop-hdfs-datanode
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -n values=DATAPROC_COMPONENTS
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ !    == *\ \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e\ * ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + in_array hadoop-hdfs-datanode COMPONENT_SERVICES
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r value=hadoop-hdfs-datanode
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -n values=COMPONENT_SERVICES
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ !  hadoop-hdfs-namenode hadoop-hdfs-datanode hadoop-hdfs-zkfc hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hive-metastore hive-server2 mysql-server spark-history-server  == *\ \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e\ * ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + continue
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + for service in ${DATAPROC_WORKER_SERVICES}
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + in_array hadoop-yarn-nodemanager DATAPROC_COMPONENTS
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r value=hadoop-yarn-nodemanager
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -n values=DATAPROC_COMPONENTS
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ !    == *\ \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r\ * ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + in_array hadoop-yarn-nodemanager COMPONENT_SERVICES
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r value=hadoop-yarn-nodemanager
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -n values=COMPONENT_SERVICES
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ !  hadoop-hdfs-namenode hadoop-hdfs-datanode hadoop-hdfs-zkfc hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hive-metastore hive-server2 mysql-server spark-history-server  == *\ \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r\ * ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + enable_service hadoop-yarn-nodemanager
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r service=hadoop-yarn-nodemanager
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r unit=hadoop-yarn-nodemanager.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + retry_constant_short systemctl enable hadoop-yarn-nodemanager.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + retry_constant_custom 30 1 systemctl enable hadoop-yarn-nodemanager.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r max_retry_time=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r retry_delay=1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cmd=('systemctl' 'enable' 'hadoop-yarn-nodemanager.service')
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r cmd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r max_retries=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: About to run 'systemctl enable hadoop-yarn-nodemanager.service' with retries...
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: hadoop-yarn-nodemanager.service is not a native service, redirecting to systemd-sysv-install.
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Executing: /lib/systemd/systemd-sysv-install enable hadoop-yarn-nodemanager
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: 'systemctl enable hadoop-yarn-nodemanager.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r drop_in_dir=/etc/systemd/system/hadoop-yarn-nodemanager.service.d
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + mkdir -p /etc/systemd/system/hadoop-yarn-nodemanager.service.d
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local props
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ retry_constant_short systemctl show hadoop-yarn-nodemanager.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ retry_constant_custom 30 1 systemctl show hadoop-yarn-nodemanager.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ local -r retry_delay=1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ cmd=('systemctl' 'show' 'hadoop-yarn-nodemanager.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ local -r cmd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ local -r max_retries=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ local reenable_x=false
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: About to run 'systemctl show hadoop-yarn-nodemanager.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: 'systemctl show hadoop-yarn-nodemanager.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ return 0
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + props='Restart=no
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: RemainAfterExit=no'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ hadoop-yarn-nodemanager != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ hadoop-yarn-nodemanager != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ dirname /etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + mkdir -p /etc/systemd/system/common
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ hadoop-yarn-nodemanager == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ hadoop-yarn-nodemanager == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_metadata_worker_count
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_WORKER_COUNT attributes/dataproc-worker-count
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r worker_count=3
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ 3 != 0 ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + ln -s -f /etc/systemd/system/common/agent-gate.conf /etc/systemd/system/hadoop-yarn-nodemanager.service.d
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + ln -s -f /etc/systemd/system/common/worker-restart.conf /etc/systemd/system/hadoop-yarn-nodemanager.service.d
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_ubuntu
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ os_id
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ grep '^ID=' /etc/os-release
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ xargs
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ cut -d= -f2
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ debian == \u\b\u\n\t\u ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + loginfo 'Generating helper scripts'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + echo 'Generating helper scripts'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Generating helper scripts
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ (( i = 0 ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ (( i < 1 ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ echo MASTER_HOSTNAME_0=cluster-dip-01-m
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ (( i++ ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ (( i < 1 ))
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ cat /usr/local/share/google/dataproc/bdutil/configure_keys.sh /usr/local/share/google/dataproc/bdutil/configure_hadoop.sh /usr/local/share/google/dataproc/bdutil/configure_connectors.sh /usr/local/share/google/dataproc/bdutil/configure_docker.sh /usr/local/share/google/dataproc/bdutil/configure_metadata_proxy.sh
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cp -r /usr/local/share/google/dataproc/bdutil/conf/bq-mapred-template.xml /usr/local/share/google/dataproc/bdutil/conf/capacity-scheduler-template.xml /usr/local/share/google/dataproc/bdutil/conf/collectd /usr/local/share/google/dataproc/bdutil/conf/collectd_default_filtered_write.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_flink_statsd_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_hdfs_jmx_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_hivemetastore_jmx_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_hiveserver2_jmx_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_load_jmx_plugin.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_processes_default_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_shs_jmx_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_spark_buffer_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_spark_default_metrics.conf /usr/local/shar
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: e/google/dataproc/bdutil/conf/collectd_spark_yarn_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_without_monitoring_agent_defaults.conf /usr/local/share/google/dataproc/bdutil/conf/collectd_yarn_jmx_metrics.conf /usr/local/share/google/dataproc/bdutil/conf/core-ha-template.xml /usr/local/share/google/dataproc/bdutil/conf/core-template.xml /usr/local/share/google/dataproc/bdutil/conf/distcp-template.xml /usr/local/share/google/dataproc/bdutil/conf/gcs-core-template.xml /usr/local/share/google/dataproc/bdutil/conf/hdfs-ha-template.xml /usr/local/share/google/dataproc/bdutil/conf/hdfs-simplification-ha-mixins.xml /usr/local/share/google/dataproc/bdutil/conf/hdfs-simplification-mixins.xml /usr/local/share/google/dataproc/bdutil/conf/hdfs-template.xml /usr/local/share/google/dataproc/bdutil/conf/hive-ha-mixins.xml /usr/local/share/google/dataproc/bdutil/conf/hive-template.xml /usr/local/share/google/dataproc/bdutil/conf/knox /usr/local/share/google/dataproc/bdutil/conf/mapred-template.xml /usr/
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: local/share/google/dataproc/bdutil/conf/otel /usr/local/share/google/dataproc/bdutil/conf/otel_gcs_connector_metrics.yaml /usr/local/share/google/dataproc/bdutil/conf/otel_spark_default_metrics.yaml /usr/local/share/google/dataproc/bdutil/conf/yarn-ha-template.xml /usr/local/share/google/dataproc/bdutil/conf/yarn-simplification-ha-mixins.xml /usr/local/share/google/dataproc/bdutil/conf/yarn-simplification-mixins.xml /usr/local/share/google/dataproc/bdutil/conf/yarn-template.xml /tmp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cp /usr/local/share/google/dataproc/bdutil/configure_mrv2_mem.py /tmp
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + chmod +x configure_mrv2_mem.py
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + loginfo 'Running helper scripts'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + echo 'Running helper scripts'
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Running helper scripts
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.localssd.mount.enable
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + MOUNT_DISKS_ENABLED=
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ '' == \f\a\l\s\e ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + DATAPROC_MOUNT_SERVICE_FILE=/usr/lib/systemd/system/google-dataproc-disk-mount.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + chmod +x /usr/local/share/google/dataproc/bdutil/mount_disks.sh
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + chmod 644 /usr/lib/systemd/system/google-dataproc-disk-mount.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + enable_and_start_service google-dataproc-disk-mount
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r service=google-dataproc-disk-mount
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + enable_service google-dataproc-disk-mount
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r service=google-dataproc-disk-mount
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r unit=google-dataproc-disk-mount.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + retry_constant_short systemctl enable google-dataproc-disk-mount.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + retry_constant_custom 30 1 systemctl enable google-dataproc-disk-mount.service
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r max_retry_time=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r retry_delay=1
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + cmd=('systemctl' 'enable' 'google-dataproc-disk-mount.service')
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r cmd
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local -r max_retries=30
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: About to run 'systemctl enable google-dataproc-disk-mount.service' with retries...
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Created symlink /etc/systemd/system/multi-user.target.wants/google-dataproc-disk-mount.service  /lib/systemd/system/google-dataproc-disk-mount.service.
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Created symlink /etc/systemd/system/hadoop-hdfs-namenode.service.wants/google-dataproc-disk-mount.service  /lib/systemd/system/google-dataproc-disk-mount.service.
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Created symlink /etc/systemd/system/hadoop-hdfs-datanode.service.wants/google-dataproc-disk-mount.service  /lib/systemd/system/google-dataproc-disk-mount.service.
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Created symlink /etc/systemd/system/hadoop-yarn-resourcemanager.service.wants/google-dataproc-disk-mount.service  /lib/systemd/system/google-dataproc-disk-mount.service.
<13>Apr 27 18:07:23 dataproc-startup-script[1253]: Created symlink /etc/systemd/system/hadoop-yarn-nodemanager.service.wants/google-dataproc-disk-mount.service  /lib/systemd/system/google-dataproc-disk-mount.service.
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: 'systemctl enable google-dataproc-disk-mount.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r drop_in_dir=/etc/systemd/system/google-dataproc-disk-mount.service.d
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + mkdir -p /etc/systemd/system/google-dataproc-disk-mount.service.d
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local props
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ retry_constant_short systemctl show google-dataproc-disk-mount.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ retry_constant_custom 30 1 systemctl show google-dataproc-disk-mount.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -r retry_delay=1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ cmd=('systemctl' 'show' 'google-dataproc-disk-mount.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -r cmd
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -r max_retries=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: About to run 'systemctl show google-dataproc-disk-mount.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: 'systemctl show google-dataproc-disk-mount.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ return 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + props='Restart=no
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: RemainAfterExit=yes'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ google-dataproc-disk-mount != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ google-dataproc-disk-mount != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ Restart=no
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: RemainAfterExit=yes == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ Restart=no
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: RemainAfterExit=yes == *\R\e\m\a\i\n\A\f\t\e\r\E\x\i\t\=\n\o* ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ google-dataproc-disk-mount == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ google-dataproc-disk-mount == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + start_service google-dataproc-disk-mount
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + start_services google-dataproc-disk-mount
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + units=('google-dataproc-disk-mount.service')
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r units
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + retry_constant_short systemctl start google-dataproc-disk-mount.service
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + retry_constant_custom 30 1 systemctl start google-dataproc-disk-mount.service
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r max_retry_time=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r retry_delay=1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cmd=('systemctl' 'start' 'google-dataproc-disk-mount.service')
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r cmd
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r max_retries=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: About to run 'systemctl start google-dataproc-disk-mount.service' with retries...
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: 'systemctl start google-dataproc-disk-mount.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bash -e configuration_script.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly METADATA_HOST=metadata.google.internal
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + METADATA_HOST=metadata.google.internal
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly INSTANCE_METADATA_PATH=computeMetadata/v1/instance
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + INSTANCE_METADATA_PATH=computeMetadata/v1/instance
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly IDENTITY_KEY=service-accounts/default/identity
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + IDENTITY_KEY=service-accounts/default/identity
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly GUEST_ATTRIBUTE_PATH=computeMetadata/v1/instance/guest-attributes/dataproc-signed-keys
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GUEST_ATTRIBUTE_PATH=computeMetadata/v1/instance/guest-attributes/dataproc-signed-keys
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly SERIAL_DEVICE=/dev/ttyS3
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + SERIAL_DEVICE=/dev/ttyS3
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly GENERATE_KEYS_SCRIPT=/usr/bin/google-dataproc-generate-cluster-keys.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GENERATE_KEYS_SCRIPT=/usr/bin/google-dataproc-generate-cluster-keys.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly TINKEY_BINARY_PATH=/usr/local/bin/tinkey
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + TINKEY_BINARY_PATH=/usr/local/bin/tinkey
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.encryption.keygen.enabled
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cluster_keys_enabled=
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.encryption.keygen.rotation_hours 6
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cluster_keys_rotation_hours=6
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chmod u+rwx /usr/bin/google-dataproc-generate-cluster-keys.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + rm /etc/udev/rules.d/80-ttyS3.rules
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + udevadm trigger
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chown root:dialout /dev/ttyS3
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set -e
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + loginfo 'Running configure_hadoop.sh'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + echo 'Running configure_hadoop.sh'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: Running configure_hadoop.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly HADOOP_MASTER_MAPREDUCE_MEMORY_FRACTION=0.4
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + HADOOP_MASTER_MAPREDUCE_MEMORY_FRACTION=0.4
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly NODEMANAGER_MEMORY_FRACTION=0.8
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + NODEMANAGER_MEMORY_FRACTION=0.8
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly CORES_PER_MAP_TASK=1.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + CORES_PER_MAP_TASK=1.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly CORES_PER_REDUCE_TASK=2.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + CORES_PER_REDUCE_TASK=2.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly CORES_PER_APP_MASTER=2.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + CORES_PER_APP_MASTER=2.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export HADOOP_TMP_DIR=/hadoop/tmp
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + HADOOP_TMP_DIR=/hadoop/tmp
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + mkdir -p /hadoop/tmp
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export DEFAULT_NUM_MAPS=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + DEFAULT_NUM_MAPS=30
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export DEFAULT_NUM_REDUCES=12
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + DEFAULT_NUM_REDUCES=12
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ grep -c processor /proc/cpuinfo
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + NUM_CORES=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export NUM_CORES
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ python -c 'print(int(2 // 1.0))'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAP_SLOTS=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export MAP_SLOTS
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ python -c 'print(int(2 // 2.0))'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + REDUCE_SLOTS=1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export REDUCE_SLOTS
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ free -m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ awk '/^Mem:/{print $2}'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + TOTAL_MEM_MB=7949
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ python -c 'print(int(7949 * 0.4))'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + HADOOP_MR_MASTER_MEM_MB=3179
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -x configure_mrv2_mem.py ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ mktemp /tmp/mrv2_XXX_tmp_env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + TEMP_ENV_FILE=/tmp/mrv2_XER_tmp_env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + ./configure_mrv2_mem.py --output_file /tmp/mrv2_XER_tmp_env.sh --total_memory 7949 --available_memory_ratio 0.8 --total_cores 2 --cores_per_map 1.0 --cores_per_reduce 2.0 --cores_per_app_master 2.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + source /tmp/mrv2_XER_tmp_env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export YARN_MIN_MEM_MB=512
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ YARN_MIN_MEM_MB=512
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export YARN_MAX_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ YARN_MAX_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export NODEMANAGER_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ NODEMANAGER_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export APP_MASTER_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ APP_MASTER_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export CORES_PER_APP_MASTER_ROUNDED=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ CORES_PER_APP_MASTER_ROUNDED=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export APP_MASTER_JAVA_OPTS=-Xmx4915m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ APP_MASTER_JAVA_OPTS=-Xmx4915m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export MAP_MEM_MB=3072
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ MAP_MEM_MB=3072
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export CORES_PER_MAP_ROUNDED=1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ CORES_PER_MAP_ROUNDED=1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export MAP_JAVA_OPTS=-Xmx2457m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ MAP_JAVA_OPTS=-Xmx2457m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export REDUCE_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ REDUCE_MEM_MB=6144
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export CORES_PER_REDUCE_ROUNDED=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ CORES_PER_REDUCE_ROUNDED=2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ export REDUCE_JAVA_OPTS=-Xmx4915m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ REDUCE_JAVA_OPTS=-Xmx4915m
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ python -c 'print(min(32 * 1024, int(7949 / 4)))'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + HADOOP_CLIENT_MEM_MB=1987
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GC_LOG_OPTS='-Xlog:gc*:stdout:time,level,tags'
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly CLUSTER_PROPS_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + CLUSTER_PROPS_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ cut -d= -f2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ head -n1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ grep GC_OPTS /tmp/cluster/properties/yarn-env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + USER_SUPPLIED_GC_OPTS_YARN=
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -z '' ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GC_OPTS=-XX:+UseConcMarkSweepGC
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GC_JDK17_OPTS=
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ cut -d= -f2
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ grep GC_OPTS /tmp/cluster/properties/mapred-env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ head -n1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + USER_SUPPLIED_GC_OPTS_MAPRED=
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -z '' ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + GC_OPTS=-XX:+UseConcMarkSweepGC
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + DATA_DIRS_ARRAY=($(get_data_dirs))
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ get_data_dirs
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -a mount_points
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ mapfile -t mount_points
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ find '/mnt/[0-9]*/' -maxdepth 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: find: /mnt/[0-9]*/: No such file or directory
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ true
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ (( 0 ))
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ echo /
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ return
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAPRED_DIRS=/hadoop/mapred
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAPRED_DIRS_ARRAY=(${MAPRED_DIRS})
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAPRED_LOCAL_DIRS=/hadoop/mapred/local
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAPRED_LOCAL_DIRS_ARRAY=(${MAPRED_LOCAL_DIRS})
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + YARN_DIRS=/hadoop/yarn
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + YARN_DIRS_ARRAY=(${YARN_DIRS})
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ get_yarn_nm_local_dirs
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ get_data_dirs
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ local -a mount_points
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ mapfile -t mount_points
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++++ find '/mnt/[0-9]*/' -maxdepth 0
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: find: /mnt/[0-9]*/: No such file or directory
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++++ true
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ (( 0 ))
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ echo /
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: +++ return
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ data_dirs=('/')
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ local -r data_dirs
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: ++ echo /hadoop/yarn/nm-local-dir
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + NODEMANAGER_LOCAL_DIRS=/hadoop/yarn/nm-local-dir
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + NODEMANAGER_LOCAL_DIRS_ARRAY=(${NODEMANAGER_LOCAL_DIRS})
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + mkdir -p /hadoop/mapred/local /hadoop/yarn/nm-local-dir
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chgrp hadoop -L -R /hadoop /hadoop/tmp
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chown -L -R mapred:hadoop /hadoop/mapred
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chown -L -R yarn:hadoop /hadoop/yarn
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chmod g+rwx -R /hadoop /hadoop/mapred /hadoop/yarn
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + chmod 777 -R /hadoop/tmp
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export MAPRED_LOCAL_DIRS=/hadoop/mapred/local
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + MAPRED_LOCAL_DIRS=/hadoop/mapred/local
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + export NODEMANAGER_LOCAL_DIRS=/hadoop/yarn/nm-local-dir
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + NODEMANAGER_LOCAL_DIRS=/hadoop/yarn/nm-local-dir
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + YARN_ENV_FILE=/etc/hadoop/conf/yarn-env.sh
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ -f /etc/hadoop/conf/yarn-env.sh ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly CORE_TEMPLATE=core-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + CORE_TEMPLATE=core-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + readonly YARN_TEMPLATE=yarn-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + YARN_TEMPLATE=yarn-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + merge_hadoop_configurations core-site.xml core-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r config=core-site.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r template=core-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/core-site.xml --source_configuration_file core-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + merge_hadoop_configurations mapred-site.xml mapred-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r config=mapred-site.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r template=mapred-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/mapred-site.xml --source_configuration_file mapred-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + merge_hadoop_configurations yarn-site.xml yarn-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r template=yarn-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/yarn-site.xml --source_configuration_file yarn-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + merge_hadoop_configurations capacity-scheduler.xml capacity-scheduler-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r config=capacity-scheduler.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r template=capacity-scheduler-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/capacity-scheduler.xml --source_configuration_file capacity-scheduler-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + merge_hadoop_configurations distcp-default.xml distcp-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r config=distcp-default.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + local -r template=distcp-template.xml
<13>Apr 27 18:07:24 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/distcp-default.xml --source_configuration_file distcp-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property mapred-site.xml mapreduce.application.classpath '$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*'
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=mapred-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=mapreduce.application.classpath
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r 'property_value=$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*'
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/mapred-site.xml --name mapreduce.application.classpath --value '$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*' --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property mapred-site.xml mapreduce.client.submit.file.replication 2
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=mapred-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=mapreduce.client.submit.file.replication
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=2
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/mapred-site.xml --name mapreduce.client.submit.file.replication --value 2 --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.application.classpath '$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*'
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.application.classpath
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r 'property_value=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*'
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.application.classpath --value '$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     $HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,
<13>Apr 27 18:07:25 dataproc-startup-script[1253]:     /usr/local/share/google/dataproc/lib/*' --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.nodemanager.env-whitelist PATH,JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME,LD_LIBRARY_PATH,LANG,TZ
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.nodemanager.env-whitelist
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=PATH,JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME,LD_LIBRARY_PATH,LANG,TZ
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.nodemanager.env-whitelist --value PATH,JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME,LD_LIBRARY_PATH,LANG,TZ --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.nm.liveness-monitor.expiry-interval-ms 120000
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.nm.liveness-monitor.expiry-interval-ms
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=120000
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.nm.liveness-monitor.expiry-interval-ms --value 120000 --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.log-aggregation-enable false
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.log-aggregation-enable
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=false
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.log-aggregation-enable --value false --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + ZK_QUORUM=cluster-dip-01-m:2181,:2181,:2181
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property hdfs-site.xml dfs.namenode.file.close.num-committed-allowed 1
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=hdfs-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=dfs.namenode.file.close.num-committed-allowed
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=1
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.file.close.num-committed-allowed --value 1 --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property core-site.xml hadoop.http.filter.initializers org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=core-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=hadoop.http.filter.initializers
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/core-site.xml --name hadoop.http.filter.initializers --value org.apache.hadoop.security.HttpCrossOriginFilterInitializer,org.apache.hadoop.http.lib.StaticUserWebFilter --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.resourcemanager.webapp.cross-origin.enabled true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.resourcemanager.webapp.cross-origin.enabled
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.resourcemanager.webapp.cross-origin.enabled --value true --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.timeline-service.http-cross-origin.enabled true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.timeline-service.http-cross-origin.enabled
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.http-cross-origin.enabled --value true --clobber
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.timeline-service.enabled true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_name=yarn.timeline-service.enabled
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + local -r property_value=true
<13>Apr 27 18:07:25 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.enabled --value true --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.timeline-service.hostname cluster-dip-01-m
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_name=yarn.timeline-service.hostname
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_value=cluster-dip-01-m
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.hostname --value cluster-dip-01-m --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.timeline-service.bind-host 0.0.0.0
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_name=yarn.timeline-service.bind-host
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_value=0.0.0.0
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.bind-host --value 0.0.0.0 --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.resourcemanager.system-metrics-publisher.enabled true
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_name=yarn.resourcemanager.system-metrics-publisher.enabled
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_value=true
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.resourcemanager.system-metrics-publisher.enabled --value true --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.timeline-service.generic-application-history.enabled true
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_name=yarn.timeline-service.generic-application-history.enabled
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_value=true
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.generic-application-history.enabled --value true --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + set_hadoop_property core-site.xml hadoop.security.token.service.use_ip false
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r config=core-site.xml
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_name=hadoop.security.token.service.use_ip
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + local -r property_value=false
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/core-site.xml --name hadoop.security.token.service.use_ip --value false --clobber
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ get_dataproc_property am.primary_only
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + AM_ON_PRIMARY_WORKER_ENABLED=false
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ get_metadata_datanode_enabled
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ get_dataproc_metadata DATAPROC_METADATA_DATANODE_ENABLED attributes/dataproc-datanode-enabled
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + DATAPROC_DATANODE_ENABLED=true
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ create_or_validate_include_file_path
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local include_path
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: +++ get_include_file_path
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: +++ local include_path
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++++ /usr/share/google/get_metadata_value attributes/dataproc-include-file-location
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: +++ include_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: +++ [[ -z gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include ]]
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: +++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ include_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ [[ gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include == gs://* ]]
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ loginfo 'Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include'
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ echo 'Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include'
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ retry_constant_custom 10 3 gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local -r max_retry_time=10
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local -r retry_delay=3
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ cmd=('gcs_file_exists' 'gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include')
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local -r cmd
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local -r max_retries=3
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ local reenable_x=false
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:26 dataproc-startup-script[1253]: About to run 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include' with retries...
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include' succeeded after 1 execution(s).
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ return 0
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: + INCLUDE_PATH=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ create_or_validate_exclude_file_path
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local exclude_path
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: +++ get_exclude_file_path
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: +++ local exclude_path
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++++ /usr/share/google/get_metadata_value attributes/dataproc-exclude-file-location
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: +++ exclude_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: +++ [[ -z gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml ]]
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: +++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ exclude_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ [[ gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml == gs://* ]]
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ loginfo 'Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml'
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ echo 'Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml'
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ retry_constant_custom 10 3 gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local -r max_retry_time=10
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local -r retry_delay=3
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ cmd=('gcs_file_exists' 'gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml')
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local -r cmd
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local -r max_retries=3
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ local reenable_x=false
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:28 dataproc-startup-script[1253]: About to run 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml' with retries...
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml' succeeded after 1 execution(s).
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ return 0
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + EXCLUDE_PATH=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.resourcemanager.nodes.include-path gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r property_name=yarn.resourcemanager.nodes.include-path
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r property_value=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.resourcemanager.nodes.include-path --value gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include --clobber
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + set_hadoop_property yarn-site.xml yarn.resourcemanager.nodes.exclude-path gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r property_name=yarn.resourcemanager.nodes.exclude-path
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r property_value=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.resourcemanager.nodes.exclude-path --value gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml --clobber
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value attributes/master-run-driver-location
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + MASTER_RUN_DRIVER_LOCATION=LOCAL
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ LOCAL == \Y\A\R\N ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + readonly YARN_SIMPLIFICATION_MIXINS=yarn-simplification-mixins.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + YARN_SIMPLIFICATION_MIXINS=yarn-simplification-mixins.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + merge_hadoop_configurations yarn-site.xml /usr/local/share/google/dataproc/bdutil/conf/yarn-simplification-mixins.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r config=yarn-site.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r template=/usr/local/share/google/dataproc/bdutil/conf/yarn-simplification-mixins.xml
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/yarn-site.xml --source_configuration_file /usr/local/share/google/dataproc/bdutil/conf/yarn-simplification-mixins.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + is_component_selected kerberos
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r component=kerberos
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_dataproc_property yarn.docker.enable
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + ENABLE_DOCKER_YARN=
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ -z '' ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_dataproc_property docker.yarn.enable
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + ENABLE_DOCKER_YARN=
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + is_component_selected docker-ce
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local -r component=docker-ce
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *docker-ce* ]]
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + set -e
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + loginfo 'Running configure_connectors.sh'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + echo 'Running configure_connectors.sh'
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: Running configure_connectors.sh
<13>Apr 27 18:07:29 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/core-site.xml --source_configuration_file gcs-core-template.xml --resolve_environment_variables --create_if_absent --noclobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/mapred-site.xml --source_configuration_file bq-mapred-template.xml --resolve_environment_variables --create_if_absent --noclobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set -euxo pipefail
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/components/shared/docker.sh
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ readonly DOCKER_PATH=/var/lib/docker
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ DOCKER_PATH=/var/lib/docker
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ readonly GCR_CREDENTIAL_HELPER_VERSION=2.0.0
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ GCR_CREDENTIAL_HELPER_VERSION=2.0.0
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_component_selected docker-ce
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r component=docker-ce
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *docker-ce* ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly RUN_SCRIPT_PATH=/usr/local/share/google/dataproc/metadata-proxy.sh
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + RUN_SCRIPT_PATH=/usr/local/share/google/dataproc/metadata-proxy.sh
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly PROXY_SERVICE_CONF=/usr/lib/systemd/system/metadata-proxy.service
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + PROXY_SERVICE_CONF=/usr/lib/systemd/system/metadata-proxy.service
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly METADATA_ADDRESS=169.254.169.254
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + METADATA_ADDRESS=169.254.169.254
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly METADATA_PORT=80
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + METADATA_PORT=80
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly METADATA_PASSTHROUGH_PORT=987
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + METADATA_PASSTHROUGH_PORT=987
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly METADATA_PROXY_PORT=988
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + METADATA_PROXY_PORT=988
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly POLLING_SCRIPT_PATH=/usr/local/share/google/dataproc/poll-metadata.sh
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + POLLING_SCRIPT_PATH=/usr/local/share/google/dataproc/poll-metadata.sh
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly POLLING_SERVICE_CONF=/usr/lib/systemd/system/metadata-credentials-polling.service
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + POLLING_SERVICE_CONF=/usr/lib/systemd/system/metadata-credentials-polling.service
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly 'TOKEN_SOURCE_METADATA=TOKEN FROM METADATA ATTRIBUTES'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + TOKEN_SOURCE_METADATA='TOKEN FROM METADATA ATTRIBUTES'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly 'TOKEN_SOURCE_GCS=TOKEN FROM GCS'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + TOKEN_SOURCE_GCS='TOKEN FROM GCS'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value attributes/dataproc-bucket
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + CONFIGBUCKET=dataproc-staging-us-east1-679657336577-kutp8kah
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly CONFIGBUCKET
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value attributes/dataproc-cluster-uuid
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + CLUSTER_UUID=0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly CLUSTER_UUID
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value id
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + INSTANCE_UUID=1417639016641318062
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly INSTANCE_UUID
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly TOKEN_METADATA_ATTRIBUTE=attributes/dataproc-injected-credentials
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + TOKEN_METADATA_ATTRIBUTE=attributes/dataproc-injected-credentials
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.metadata.proxy.enabled
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + METADATA_PROXY_ENABLED=
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly METADATA_PROXY_ENABLED
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.exclusive.user
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + DATAPROC_EXCLUSIVE_USER=
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly DATAPROC_EXCLUSIVE_USER
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.personal-auth.override-user-display-name
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + PERSONAL_AUTH_OVERRIDE_USER_DISPLAY_NAME=
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly PERSONAL_AUTH_OVERRIDE_USER_DISPLAY_NAME
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property internal.euc.user
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + SERVERLESS_EUC_USER=
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly SERVERLESS_EUC_USER
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ standard != \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_component_selected yarn
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r component=yarn
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *yarn* ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default yarn.log-aggregation.enabled false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + LOG_AGGREGATION_ENABLED=true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly LOG_AGGREGATION_ENABLED
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + loginfo 'Enabling YARN log aggregation.'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + echo 'Enabling YARN log aggregation.'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: Enabling YARN log aggregation.
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_yarn_site yarn.log-aggregation-enable true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation-enable
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/yarn-site.xml yarn.log-aggregation-enable true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation-enable
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.log-aggregation-enable --value true --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_component_selected kerberos
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r component=kerberos
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly YARN_LOG_SERVER_SCHEMA=http
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + YARN_LOG_SERVER_SCHEMA=http
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly YARN_LOG_SERVER_PORT=19888
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + YARN_LOG_SERVER_PORT=19888
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + readonly YARN_LOG_SERVER_URL=http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + YARN_LOG_SERVER_URL=http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_yarn_site yarn.log.server.url http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log.server.url
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/yarn-site.xml yarn.log.server.url http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log.server.url
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=http://cluster-dip-01-m:19888/jobhistory/logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.log.server.url --value http://cluster-dip-01-m:19888/jobhistory/logs --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ -n dataproc-temp-us-east1-679657336577-juievcnm ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_yarn_site yarn.nodemanager.remote-app-log-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.nodemanager.remote-app-log-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/yarn-site.xml yarn.nodemanager.remote-app-log-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.nodemanager.remote-app-log-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.nodemanager.remote-app-log-dir --value gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/yarn-logs --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_yarn_site yarn.log-aggregation.file-formats IFile,TFile
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation.file-formats
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=IFile,TFile
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/yarn-site.xml yarn.log-aggregation.file-formats IFile,TFile
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation.file-formats
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=IFile,TFile
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=IFile,TFile
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.log-aggregation.file-formats --value IFile,TFile --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_yarn_site yarn.log-aggregation.file-controller.IFile.class org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation.file-controller.IFile.class
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/yarn-site.xml yarn.log-aggregation.file-controller.IFile.class org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=yarn.log-aggregation.file-controller.IFile.class
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.log-aggregation.file-controller.IFile.class --value org.apache.hadoop.yarn.logaggregation.filecontroller.ifile.LogAggregationIndexedFileController --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default job.history.to-gcs.enabled false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + PERSIST_HISTORY_TO_GCS=true
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + loginfo 'Enabling persisting MapReduce job history files to GCS.'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + echo 'Enabling persisting MapReduce job history files to GCS.'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: Enabling persisting MapReduce job history files to GCS.
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ -n dataproc-temp-us-east1-679657336577-juievcnm ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_mapred_site mapreduce.jobhistory.done-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.done-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/mapred-site.xml mapreduce.jobhistory.done-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/mapred-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.done-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/mapred-site.xml --name mapreduce.jobhistory.done-dir --value gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_mapred_site mapreduce.jobhistory.intermediate-done-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.intermediate-done-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/mapred-site.xml mapreduce.jobhistory.intermediate-done-dir gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/mapred-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.intermediate-done-dir
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/mapred-site.xml --name mapreduce.jobhistory.intermediate-done-dir --value gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/mapreduce-job-history/done_intermediate --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_mapred_site mapreduce.jobhistory.move.interval-ms 1000
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.move.interval-ms
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=1000
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + set_property_in_xml /etc/hadoop/conf/mapred-site.xml mapreduce.jobhistory.move.interval-ms 1000
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r xml_file=/etc/hadoop/conf/mapred-site.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r name=mapreduce.jobhistory.move.interval-ms
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r value=1000
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r mode=overwrite
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r delimiter=,
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local skip=false
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local old_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local new_value
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + new_value=1000
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig set_property --configuration_file /etc/hadoop/conf/mapred-site.xml --name mapreduce.jobhistory.move.interval-ms --value 1000 --create_if_absent --clobber
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.users
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + DATAPROC_USERS=
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ -n '' ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + is_component_selected kerberos
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local -r component=kerberos
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local activated_components
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_components_to_activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + loginfo 'Merging user-specified cluster properties'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + echo 'Merging user-specified cluster properties'
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: Merging user-specified cluster properties
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + merge_xml_properties /tmp/cluster/properties/capacity-scheduler.xml /etc/hadoop/conf/capacity-scheduler.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/capacity-scheduler.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/capacity-scheduler.xml
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/capacity-scheduler.xml ]]
<13>Apr 27 18:07:30 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/capacity-scheduler.xml --source_configuration_file /tmp/cluster/properties/capacity-scheduler.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/capacity-scheduler.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/capacity-scheduler.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/capacity-scheduler.xml.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_xml_properties /tmp/cluster/properties/core.xml /etc/hadoop/conf/core-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/core.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/core-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/core.xml ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/core-site.xml --source_configuration_file /tmp/cluster/properties/core.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/core.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/core.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/core.xml.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_xml_properties /tmp/cluster/properties/distcp.xml /etc/hadoop/conf/distcp-default.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/distcp.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/distcp-default.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/distcp.xml ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/distcp-default.xml --source_configuration_file /tmp/cluster/properties/distcp.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/distcp.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/distcp.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/distcp.xml.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_xml_properties /tmp/cluster/properties/mapred.xml /etc/hadoop/conf/mapred-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/mapred.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/mapred-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/mapred.xml ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/mapred-site.xml --source_configuration_file /tmp/cluster/properties/mapred.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/mapred.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/mapred.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/mapred.xml.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_xml_properties /tmp/cluster/properties/yarn.xml /etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/yarn.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/yarn-site.xml
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/yarn.xml ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/yarn-site.xml --source_configuration_file /tmp/cluster/properties/yarn.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/yarn.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/yarn.xml.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/yarn.xml.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_sh_env_vars /tmp/cluster/properties/hadoop-env.sh /etc/hadoop/conf/hadoop-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/hadoop-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/hadoop-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/hadoop-env.sh ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + cat /tmp/cluster/properties/hadoop-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/hadoop-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/hadoop-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/hadoop-env.sh.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_sh_env_vars /tmp/cluster/properties/mapred-env.sh /etc/hadoop/conf/mapred-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/mapred-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/mapred-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/mapred-env.sh ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + cat /tmp/cluster/properties/mapred-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/mapred-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/mapred-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/mapred-env.sh.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_sh_env_vars /tmp/cluster/properties/yarn-env.sh /etc/hadoop/conf/yarn-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local src=/tmp/cluster/properties/yarn-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local dest=/etc/hadoop/conf/yarn-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/yarn-env.sh ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + cat /tmp/cluster/properties/yarn-env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/yarn-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/yarn-env.sh.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/yarn-env.sh.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + merge_java_properties /tmp/cluster/properties/hadoop-log4j.properties /etc/hadoop/conf/log4j.properties
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local -r src=/tmp/cluster/properties/hadoop-log4j.properties
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local -r dest=/etc/hadoop/conf/log4j.properties
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ ! -f /tmp/cluster/properties/hadoop-log4j.properties ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + cat /tmp/cluster/properties/hadoop-log4j.properties
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Merged /tmp/cluster/properties/hadoop-log4j.properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Merged /tmp/cluster/properties/hadoop-log4j.properties.'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Merged /tmp/cluster/properties/hadoop-log4j.properties.
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ -f /etc/hbase/conf/hbase-site.xml ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + DATAPROC_COMPONENTS=(${DATAPROC_OPTIONAL_COMPONENTS})
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'DATAPROC_COMPONENTS: dpms-proxy hdfs hive-metastore hive-server2 kerberos knox mapreduce mysql npd proxy-agent spark tez yarn zookeeper-server jupyter fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce hive-webhcat-server zeppelin flink hudi pig ranger solr-server trino iceberg delta jupyter-kernel-gateway'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: DATAPROC_COMPONENTS: dpms-proxy hdfs hive-metastore hive-server2 kerberos knox mapreduce mysql npd proxy-agent spark tez yarn zookeeper-server jupyter fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce hive-webhcat-server zeppelin flink hudi pig ranger solr-server trino iceberg delta jupyter-kernel-gateway
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + ARTIFACTS_TO_KEEP=("${SERVICES[@]}" ${DATAPROC_COMMON_PACKAGES})
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'ARTIFACTS_TO_KEEP: autofs bash-completion bc chrony git jq unzip vim wget bigtop-utils hadoop-client hadoop-lzo temurin-11-jdk=11.0.20.1.0+1 temurin-17-jdk hdfs libhdfs0 hive-metastore hive-server2 hive-hcatalog kerberos mapreduce mysql mysql-connector-j npd spark tez yarn zookeeper-server texlive-xetex default-jre- texlive-fonts-recommended texlive-plain-generic fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce flink hudi pig ranger trino iceberg delta libapr1 libatlas3-base libjansi-java libsnappy-dev libssl-dev libzstd-dev openssl uuid-runtime linux-headers-cloud-amd64 linux-image-cloud-amd64 libopenblas0 netcat-openbsd python3-numpy python3-pip python3-requests python3-setuptools'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ARTIFACTS_TO_KEEP: autofs bash-completion bc chrony git jq unzip vim wget bigtop-utils hadoop-client hadoop-lzo temurin-11-jdk=11.0.20.1.0+1 temurin-17-jdk hdfs libhdfs0 hive-metastore hive-server2 hive-hcatalog kerberos mapreduce mysql mysql-connector-j npd spark tez yarn zookeeper-server texlive-xetex default-jre- texlive-fonts-recommended texlive-plain-generic fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce flink hudi pig ranger trino iceberg delta libapr1 libatlas3-base libjansi-java libsnappy-dev libssl-dev libzstd-dev openssl uuid-runtime linux-headers-cloud-amd64 linux-image-cloud-amd64 libopenblas0 netcat-openbsd python3-numpy python3-pip python3-requests python3-setuptools
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + COMPONENTS_TO_ACTIVATE=($(intersection SELECTED_COMPONENTS ARTIFACTS_TO_KEEP))
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ intersection SELECTED_COMPONENTS ARTIFACTS_TO_KEEP
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n values=SELECTED_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n filter=ARTIFACTS_TO_KEEP
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ comm -12 /dev/fd/63 /dev/fd/62
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' autofs bash-completion bc chrony git jq unzip vim wget bigtop-utils hadoop-client hadoop-lzo temurin-11-jdk=11.0.20.1.0+1 temurin-17-jdk hdfs libhdfs0 hive-metastore hive-server2 hive-hcatalog kerberos mapreduce mysql mysql-connector-j npd spark tez yarn zookeeper-server texlive-xetex default-jre- texlive-fonts-recommended texlive-plain-generic fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce flink hudi pig ranger trino iceberg delta libapr1 libatlas3-base libjansi-java libsnappy-dev libssl-dev libzstd-dev openssl uuid-runtime linux-headers-cloud-amd64 linux-image-cloud-amd64 libopenblas0 netcat-openbsd python3-numpy python3-pip python3-requests python3-setuptools
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'COMPONENTS_TO_ACTIVATE: earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: COMPONENTS_TO_ACTIVATE: earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + loginfo 'Generating post_hdfs_env.sh'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'Generating post_hdfs_env.sh'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: Generating post_hdfs_env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + chmod +x /usr/local/share/google/dataproc/bdutil/components/post_hdfs_env.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + NON_ACTIVATED_COMPONENTS=($(difference DATAPROC_COMPONENTS COMPONENTS_TO_ACTIVATE))
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ difference DATAPROC_COMPONENTS COMPONENTS_TO_ACTIVATE
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n values=DATAPROC_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n filter=COMPONENTS_TO_ACTIVATE
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ comm -23 /dev/fd/63 /dev/fd/62
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hdfs hive-metastore hive-server2 kerberos knox mapreduce mysql npd proxy-agent spark tez yarn zookeeper-server jupyter fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce hive-webhcat-server zeppelin flink hudi pig ranger solr-server trino iceberg delta jupyter-kernel-gateway
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'NON_ACTIVATED_COMPONENTS: delta docker-ce dpms-proxy flink google-fluentd-container hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: NON_ACTIVATED_COMPONENTS: delta docker-ce dpms-proxy flink google-fluentd-container hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + ARTIFACTS_TO_UNINSTALL+=($(difference NON_ACTIVATED_COMPONENTS ARTIFACTS_TO_UNINSTALL))
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ difference NON_ACTIVATED_COMPONENTS ARTIFACTS_TO_UNINSTALL
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n values=NON_ACTIVATED_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n filter=ARTIFACTS_TO_UNINSTALL
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ comm -23 /dev/fd/63 /dev/fd/62
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' delta docker-ce dpms-proxy flink google-fluentd-container hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hadoop-hdfs-namenode hive-metastore hive-server2 knox proxy-agent spark-history-server hadoop-yarn-resourcemanager hive-webhcat-server solr-server jupyter-kernel-gateway hadoop-mapreduce-historyserver mysql-server hadoop-yarn-timelineserver jupyter zeppelin hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hadoop-hdfs-zkfc
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'ARTIFACTS_TO_UNINSTALL: dpms-proxy hadoop-hdfs-namenode hive-metastore hive-server2 knox proxy-agent spark-history-server hadoop-yarn-resourcemanager hive-webhcat-server solr-server jupyter-kernel-gateway hadoop-mapreduce-historyserver mysql-server hadoop-yarn-timelineserver jupyter zeppelin hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hadoop-hdfs-zkfc delta docker-ce flink google-fluentd-container hudi iceberg kerberos ranger rubix stackdriver-agent-container trino zookeeper-server'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ARTIFACTS_TO_UNINSTALL: dpms-proxy hadoop-hdfs-namenode hive-metastore hive-server2 knox proxy-agent spark-history-server hadoop-yarn-resourcemanager hive-webhcat-server solr-server jupyter-kernel-gateway hadoop-mapreduce-historyserver mysql-server hadoop-yarn-timelineserver jupyter zeppelin hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hadoop-hdfs-zkfc delta docker-ce flink google-fluentd-container hudi iceberg kerberos ranger rubix stackdriver-agent-container trino zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + COMPONENTS_TO_UNINSTALL=($(intersection ARTIFACTS_TO_UNINSTALL DATAPROC_COMPONENTS))
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ intersection ARTIFACTS_TO_UNINSTALL DATAPROC_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n values=ARTIFACTS_TO_UNINSTALL
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n filter=DATAPROC_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ comm -12 /dev/fd/63 /dev/fd/62
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hadoop-hdfs-namenode hive-metastore hive-server2 knox proxy-agent spark-history-server hadoop-yarn-resourcemanager hive-webhcat-server solr-server jupyter-kernel-gateway hadoop-mapreduce-historyserver mysql-server hadoop-yarn-timelineserver jupyter zeppelin hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hadoop-hdfs-zkfc delta docker-ce flink google-fluentd-container hudi iceberg kerberos ranger rubix stackdriver-agent-container trino zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hdfs hive-metastore hive-server2 kerberos knox mapreduce mysql npd proxy-agent spark tez yarn zookeeper-server jupyter fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce hive-webhcat-server zeppelin flink hudi pig ranger solr-server trino iceberg delta jupyter-kernel-gateway
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'COMPONENTS_TO_UNINSTALL: delta docker-ce dpms-proxy flink google-fluentd-container hive-metastore hive-server2 hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: COMPONENTS_TO_UNINSTALL: delta docker-ce dpms-proxy flink google-fluentd-container hive-metastore hive-server2 hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + PACKAGES_TO_UNINSTALL=($(difference ARTIFACTS_TO_UNINSTALL DATAPROC_COMPONENTS))
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ difference ARTIFACTS_TO_UNINSTALL DATAPROC_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n values=ARTIFACTS_TO_UNINSTALL
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ local -n filter=DATAPROC_COMPONENTS
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ comm -23 /dev/fd/63 /dev/fd/62
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hadoop-hdfs-namenode hive-metastore hive-server2 knox proxy-agent spark-history-server hadoop-yarn-resourcemanager hive-webhcat-server solr-server jupyter-kernel-gateway hadoop-mapreduce-historyserver mysql-server hadoop-yarn-timelineserver jupyter zeppelin hadoop-hdfs-secondarynamenode hadoop-hdfs-journalnode hadoop-hdfs-zkfc delta docker-ce flink google-fluentd-container hudi iceberg kerberos ranger rubix stackdriver-agent-container trino zookeeper-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ sort -u
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: +++ printf '%s\n' dpms-proxy hdfs hive-metastore hive-server2 kerberos knox mapreduce mysql npd proxy-agent spark tez yarn zookeeper-server jupyter fluentbit-ucp otel-ucp stackdriver-agent-container google-fluentd-container earlyoom rubix miniconda3 docker-ce hive-webhcat-server zeppelin flink hudi pig ranger solr-server trino iceberg delta jupyter-kernel-gateway
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + echo 'PACKAGES_TO_UNINSTALL: hadoop-hdfs-journalnode hadoop-hdfs-namenode hadoop-hdfs-secondarynamenode hadoop-hdfs-zkfc hadoop-mapreduce-historyserver hadoop-yarn-resourcemanager hadoop-yarn-timelineserver mysql-server spark-history-server'
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: PACKAGES_TO_UNINSTALL: hadoop-hdfs-journalnode hadoop-hdfs-namenode hadoop-hdfs-secondarynamenode hadoop-hdfs-zkfc hadoop-mapreduce-historyserver hadoop-yarn-resourcemanager hadoop-yarn-timelineserver mysql-server spark-history-server
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.3
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.logging.stackdriver.enable
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + STACKDRIVER_LOGGING_ENABLED=
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ 2.2 == \2\.\2 ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + is_legacy_containerized_agents_enabled
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.observability.containerised.legacy.agents.enable false
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + local -r legacy_containerised_agents_enabled=false
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + uninstall_containerised_agents
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/components/shared/containerized-obs-agents.sh
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ set -x
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ readonly LOGGING_AGENT_IMAGE=gcr.io/cloud-dataproc/observability/logging-agent:latest
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ LOGGING_AGENT_IMAGE=gcr.io/cloud-dataproc/observability/logging-agent:latest
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ readonly MONITORING_AGENT_IMAGE=gcr.io/cloud-dataproc/observability/monitoring-agent:latest
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: ++ MONITORING_AGENT_IMAGE=gcr.io/cloud-dataproc/observability/monitoring-agent:latest
<13>Apr 27 18:07:31 dataproc-startup-script[1253]: + systemctl start docker
<13>Apr 27 18:07:32 dataproc-startup-script[1253]: + docker image rm gcr.io/cloud-dataproc/observability/monitoring-agent:latest
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Untagged: gcr.io/cloud-dataproc/observability/monitoring-agent:latest
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Untagged: gcr.io/cloud-dataproc/observability/monitoring-agent@sha256:24d562eed77a6cad0edac4b3226d89d1611a49a48eb2c1217cb271d316bf0248
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Deleted: sha256:b6cc9be709f490d95853ab2de600041efea9f59a79f628e150155761d3eabbb6
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Deleted: sha256:1dc6ee519e55293f02ed83f5226dbc15bce079a89796ee5df018181b6405c8da
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Deleted: sha256:efd654cea983212c1142c0881a91d9fe2be6870f8a9cca54d672f220d0878302
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Deleted: sha256:62e5079e2bb8d6b2ff9e57f6784face341f0bf1a00003ccb281373cd8e2e57e4
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: Deleted: sha256:0f79ed81670d2b1c482a7af0ccbe1b10bfe3ea2db26a036ff526d5f55274a036
<13>Apr 27 18:07:34 dataproc-startup-script[1253]: + docker image rm gcr.io/cloud-dataproc/observability/logging-agent:latest
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Untagged: gcr.io/cloud-dataproc/observability/logging-agent:latest
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Untagged: gcr.io/cloud-dataproc/observability/logging-agent@sha256:0da0e2bd764cc12f98a18df0502bc7869e169f70a56b02b3fbabc0d06c272484
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Deleted: sha256:8928d5fa419eba3c42f8cfec245b2ec80e6c78d9c31e91f8c71f7dd0a35010f6
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Deleted: sha256:67b21cf07df3a587c3dc94f2e11514d2994e29a2cbb44e1ab0055a5da1cc8af2
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Deleted: sha256:da7310c09a42543b1f06a798bf7de5423fad0aca048f7d46154716a1d232d5c2
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Deleted: sha256:476baebdfbf7a68c50e979971fcd47d799d1b194bcf1f03c1c979e9262bcd364
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + is_rm_image
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + configure_conscrypt
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local conscrypt_enabled
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.conscrypt.provider.enable
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + conscrypt_enabled=true
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + is_arm64
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ uname -m
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ x86_64 == \a\a\r\c\h\6\4 ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r suffix=x86_64
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r conscrypt_shared_lib=/usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local conscrypt_jar
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ compgen -G '/usr/local/share/google/dataproc/conscrypt/conscrypt-openjdk-*.jar'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + conscrypt_jar=/usr/local/share/google/dataproc/conscrypt/conscrypt-openjdk-2.5.2-linux-x86_64.jar
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + is_java8
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ /usr/lib/jvm/temurin-11-jdk-amd64 == *\-\8\-* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + ln -s /usr/local/share/google/dataproc/conscrypt/conscrypt-openjdk-2.5.2-linux-x86_64.jar /usr/local/share/google/dataproc/lib/conscrypt.jar
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + copy_conscript_security_config_java11_plus /usr/lib/jvm/temurin-11-jdk-amd64 /usr/lib/jvm/temurin-11-jdk-amd64/conf /usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r jdk_home=/usr/lib/jvm/temurin-11-jdk-amd64
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r jdk_config_dir=/usr/lib/jvm/temurin-11-jdk-amd64/conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r conscrypt_shared_lib=/usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + ln -s /usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so /usr/lib/jvm/temurin-11-jdk-amd64/lib/libconscrypt_openjdk_jni.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + cp /usr/local/share/google/dataproc/java.security.conscrypt /usr/lib/jvm/temurin-11-jdk-amd64/conf/security/java.security.tmp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -n /usr/lib/jvm/temurin-17-jdk-amd64 ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + copy_conscript_security_config_java11_plus /usr/lib/jvm/temurin-17-jdk-amd64 /usr/lib/jvm/temurin-17-jdk-amd64/conf /usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r jdk_home=/usr/lib/jvm/temurin-17-jdk-amd64
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r jdk_config_dir=/usr/lib/jvm/temurin-17-jdk-amd64/conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r conscrypt_shared_lib=/usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + ln -s /usr/local/share/google/dataproc/conscrypt/libconscrypt_openjdk_jni-linux-x86_64.so /usr/lib/jvm/temurin-17-jdk-amd64/lib/libconscrypt_openjdk_jni.so
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + cp /usr/local/share/google/dataproc/java.security.conscrypt /usr/lib/jvm/temurin-17-jdk-amd64/conf/security/java.security.tmp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mv -f /usr/lib/jvm/temurin-11-jdk-amd64/conf/security/java.security.tmp /usr/lib/jvm/temurin-11-jdk-amd64/conf/security/java.security
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -n /usr/lib/jvm/temurin-17-jdk-amd64 ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mv -f /usr/lib/jvm/temurin-17-jdk-amd64/conf/security/java.security.tmp /usr/lib/jvm/temurin-17-jdk-amd64/conf/security/java.security
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + create_common_restart_drop_in_configs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + create_restart_drop_in_config /etc/systemd/system/common/restart.conf on-failure 0
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r conf_path=/etc/systemd/system/common/restart.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r restart_type=on-failure
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r interval_sec=0
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ ! -f /etc/systemd/system/common/restart.conf ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ dirname /etc/systemd/system/common/restart.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mkdir -p /etc/systemd/system/common
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + create_restart_drop_in_config /etc/systemd/system/common/worker-restart.conf always 0
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r conf_path=/etc/systemd/system/common/worker-restart.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r restart_type=always
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r interval_sec=0
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ ! -f /etc/systemd/system/common/worker-restart.conf ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ dirname /etc/systemd/system/common/worker-restart.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mkdir -p /etc/systemd/system/common
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ standard != \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + loginfo 'Pre-activating components'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo 'Pre-activating components'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Pre-activating components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + pre_activate_components earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components=('earlyoom' 'fluentbit-ucp' 'hdfs' 'hive-metastore' 'hive-server2' 'mapreduce' 'miniconda3' 'mysql' 'npd' 'otel-ucp' 'pig' 'spark' 'tez' 'yarn')
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + run_components_scripts pre-activate earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r script_type=pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + all_components=('earlyoom' 'fluentbit-ucp' 'hdfs' 'hive-metastore' 'hive-server2' 'mapreduce' 'miniconda3' 'mysql' 'npd' 'otel-ucp' 'pig' 'spark' 'tez' 'yarn')
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r all_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/earlyoom.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/earlyoom.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/mapreduce.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/mapreduce.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/miniconda3.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/miniconda3.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/npd.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/npd.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for component in "${all_components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + components+=("${component}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo 'Components with pre-activate script: fluentbit-ucp hdfs hive-metastore hive-server2 mysql otel-ucp pig spark tez yarn'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Components with pre-activate script: fluentbit-ucp hdfs hive-metastore hive-server2 mysql otel-ucp pig spark tez yarn
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r sentinel_dir=/tmp/dataproc/sentinel
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mkdir -p /tmp/dataproc/sentinel
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local names
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local scripts
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + for cmp in "${components[@]}"
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names+=("${cmp}.${script_type}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.sh")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${BDUTIL_DIR}/components/${script_type}/${cmp}.deps")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + execute_task_graph 'fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate' '/usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh' '/usr/local/share/google/dataproc/bdu
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: til/components/pre-activate/fluentbit-ucp.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.deps' /tmp/dataproc/sentinel 2.2
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo 'Generating makefile for the task graph'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Generating makefile for the task graph
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + mkdir -p /tmp/dataproc/make
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local makefile
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ mktemp /tmp/dataproc/make/makefile.XXXXXX
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + makefile=/tmp/dataproc/make/makefile.q8TdCM
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + generate_task_graph_makefile 'fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate' '/usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh' '/usr/local/share/google/da
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: taproc/bdutil/components/pre-activate/fluentbit-ucp.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.deps /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.deps' /tmp/dataproc/sentinel 2.2
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + names=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local names
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + read -r -a names
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + scripts=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local scripts
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + read -r -a scripts
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps_manifests=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifests
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + read -r -a deps_manifests
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r sentinel_dir=/tmp/dataproc/sentinel
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + task_args=('2.2')
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r task_args
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local targets
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i = 0 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=fluentbit-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/fluentbit-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/fluentbit-ucp.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: fluentbit-ucp.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=hdfs.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/hdfs.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/hdfs.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: hdfs.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/hdfs.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=hive-metastore.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/hive-metastore.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/hive-metastore.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: hive-metastore.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/hive-metastore.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=hive-server2.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ cat /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + dep_names=('mysql.pre-activate' 'hdfs.pre-activate' 'hive-metastore.pre-activate' 'tez.pre-activate')
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local dep_names
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j = 0 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j < 4 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local dep_name=mysql.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[  fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate  =~  mysql\.pre-activate  ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${sentinel_dir}/${dep_name}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j < 4 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local dep_name=hdfs.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[  fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate  =~  hdfs\.pre-activate  ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${sentinel_dir}/${dep_name}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j < 4 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local dep_name=hive-metastore.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[  fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate  =~  hive-metastore\.pre-activate  ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${sentinel_dir}/${dep_name}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j < 4 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local dep_name=tez.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[  fluentbit-ucp.pre-activate hdfs.pre-activate hive-metastore.pre-activate hive-server2.pre-activate mysql.pre-activate otel-ucp.pre-activate pig.pre-activate spark.pre-activate tez.pre-activate yarn.pre-activate  =~  tez\.pre-activate  ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps+=("${sentinel_dir}/${dep_name}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( j < 4 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/hive-server2.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/hive-server2.pre-activate: /tmp/dataproc/sentinel/mysql.pre-activate /tmp/dataproc/sentinel/hdfs.pre-activate /tmp/dataproc/sentinel/hive-metastore.pre-activate /tmp/dataproc/sentinel/tez.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: hive-server2.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/hive-server2.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=mysql.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/mysql.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/mysql.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: mysql.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/mysql.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=otel-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/otel-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/otel-ucp.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: otel-ucp.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/otel-ucp.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=pig.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/pig.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/pig.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: pig.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/pig.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=spark.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/spark.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/spark.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: spark.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/spark.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=tez.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/tez.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/tez.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: tez.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/tez.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local name=yarn.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local script=/usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps_manifest=/usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + deps=()
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local deps
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.deps ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local target=/tmp/dataproc/sentinel/yarn.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + targets+=("${target}")
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '/tmp/dataproc/sentinel/yarn.pre-activate: '
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\t@echo '\''Running task: yarn.pre-activate'\'''
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\tbash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh"; exit 1; }'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e '\ttouch /tmp/dataproc/sentinel/yarn.pre-activate\n'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i++ ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo -e 'all: /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate /tmp/dataproc/sentinel/hdfs.pre-activate /tmp/dataproc/sentinel/hive-metastore.pre-activate /tmp/dataproc/sentinel/hive-server2.pre-activate /tmp/dataproc/sentinel/mysql.pre-activate /tmp/dataproc/sentinel/otel-ucp.pre-activate /tmp/dataproc/sentinel/pig.pre-activate /tmp/dataproc/sentinel/spark.pre-activate /tmp/dataproc/sentinel/tez.pre-activate /tmp/dataproc/sentinel/yarn.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo 'Generated makefile:'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Generated makefile:
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + cat /tmp/dataproc/make/makefile.q8TdCM
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: fluentbit-ucp.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/hdfs.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: hdfs.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/hdfs.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/hive-metastore.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: hive-metastore.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/hive-metastore.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/hive-server2.pre-activate: /tmp/dataproc/sentinel/mysql.pre-activate /tmp/dataproc/sentinel/hdfs.pre-activate /tmp/dataproc/sentinel/hive-metastore.pre-activate /tmp/dataproc/sentinel/tez.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: hive-server2.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/hive-server2.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/mysql.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: mysql.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/mysql.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/otel-ucp.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: otel-ucp.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/otel-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/pig.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: pig.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/pig.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/spark.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: spark.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/spark.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/tez.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: tez.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/tez.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: /tmp/dataproc/sentinel/yarn.pre-activate: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	@echo 'Running task: yarn.pre-activate'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 	touch /tmp/dataproc/sentinel/yarn.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: all: /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate /tmp/dataproc/sentinel/hdfs.pre-activate /tmp/dataproc/sentinel/hive-metastore.pre-activate /tmp/dataproc/sentinel/hive-server2.pre-activate /tmp/dataproc/sentinel/mysql.pre-activate /tmp/dataproc/sentinel/otel-ucp.pre-activate /tmp/dataproc/sentinel/pig.pre-activate /tmp/dataproc/sentinel/spark.pre-activate /tmp/dataproc/sentinel/tez.pre-activate /tmp/dataproc/sentinel/yarn.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + echo 'Running task graph:'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Running task graph:
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + make -f /tmp/dataproc/make/makefile.q8TdCM all
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: Running task: fluentbit-ucp.pre-activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/fluentbit-ucp.sh"; exit 1; }
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ get_dataproc_property dataproc.logging.stackdriver.enable
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + STACKDRIVER_LOGGING_ENABLED=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ '' == \f\a\l\s\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + is_legacy_containerized_agents_enabled
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.observability.containerised.legacy.agents.enable false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r legacy_containerised_agents_enabled=false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-fluentbit-ucp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-fluentbit-ucp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-fluentbit-ucp[2853]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + UCP_OBSERVABILITY_BASE_PATH=/etc/ucp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + UCP_LOGGING_AGENT_PATH=/etc/ucp/logging
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + FLUENTBIT_CONF_DIR=/etc/ucp/logging/configs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + configure_ucp_logging_agent
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r fluentbit_service_file=/etc/systemd/system/fluentbit-ucp.service
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + cat
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + systemctl daemon-reload
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + systemctl enable fluentbit-ucp
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: Created symlink /etc/systemd/system/multi-user.target.wants/fluentbit-ucp.service  /etc/systemd/system/fluentbit-ucp.service.
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + setup_fluentbit_confs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + mkdir -p /etc/ucp/logging/configs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + cp -r /usr/local/share/google/dataproc/bdutil/fluentbit/append_resource_labels.lua /usr/local/share/google/dataproc/bdutil/fluentbit/dpms_proxy_fluentbit.conf /usr/local/share/google/dataproc/bdutil/fluentbit/fluentbit.conf /usr/local/share/google/dataproc/bdutil/fluentbit/hadoop_fluentbit.conf /usr/local/share/google/dataproc/bdutil/fluentbit/job-driverlogs-fluentbit.conf /usr/local/share/google/dataproc/bdutil/fluentbit/job-yarn-containerlogs-fluentbit.conf /usr/local/share/google/dataproc/bdutil/fluentbit/optional_logging /usr/local/share/google/dataproc/bdutil/fluentbit/parsers.conf /usr/local/share/google/dataproc/bdutil/fluentbit/yarn-userlogs-fluentbit.conf /etc/ucp/logging/configs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + substitute_conf_placeholders
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.logging.stackdriver.job.driver.enable
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r job_driver_logging_enabled=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_job_driver_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#INCLUDE_JOB_DRIVER_LOGS_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.logging.stackdriver.job.yarn.container.enable
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r container_logging_enabled=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local 'include_yarn_user_or_jobcontainer_logs=@INCLUDE yarn-userlogs-fluentbit.conf'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e 's#INCLUDE_YARN_USER_OR_JOBCONTAINER_LOGS_PLACEHOLDER#@INCLUDE yarn-userlogs-fluentbit.conf#' /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_dpms_proxy_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected dpms-proxy
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=dpms-proxy
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *dpms-proxy* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#INCLUDE_DPMS_PROXY_LOGS_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property_or_default dataproc.cluster.caching.enabled false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r is_caching_enabled=false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_cluster_caching_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#INCLUDE_CLUSTER_CACHING_LOGS_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property_or_default internal.node.main.memory-protection-worker.enabled false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r worker_earlyoom_enabled=true
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_earlyoom_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ Worker == \W\o\r\k\e\r ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + include_earlyoom_logs='@INCLUDE optional_logging/dataproc-earlyoom-fluentbit.conf'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e 's#INCLUDE_EARLYOOM_LOGS_PLACEHOLDER#@INCLUDE optional_logging/dataproc-earlyoom-fluentbit.conf#' /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + substitute_optional_hadoop_dirs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local optional_components_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected presto
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=presto
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *presto* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected trino
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=trino
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *trino* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected flink
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=flink
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *flink* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected druid
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=druid
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *druid* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected hbase
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=hbase
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *hbase* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected ranger
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=ranger
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *ranger* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_component_selected solr
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local -r component=solr
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local activated_components
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_components_to_activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *solr* ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#OPTIONAL_COMPONENTS_PLACEHOLDER## /etc/ucp/logging/configs/hadoop_fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + mkdir -p /var/log/google-dataproc-job
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + mkdir -p /var/log/cloud-sql-proxy
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + mkdir -p /var/log/hadoop-yarn
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + chown yarn:hadoop -R /var/log/hadoop-yarn
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + mkdir -p /var/log/hadoop-yarn/userlogs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + chown yarn:yarn -R /var/log/hadoop-yarn/userlogs
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + configure_extended_logging
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_extended_logs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_extended_logging_enabled
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local extended_logging_enabled=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property_or_default dataproc.logging.extended.enabled false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + extended_logging_enabled=false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#INCLUDE_EXTENDED_LOGS_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + configure_syslog
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local include_syslogs=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + is_syslog_logging_enabled
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + local syslog_enabled
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ get_dataproc_property_or_default dataproc.logging.syslog.enabled false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ set +x
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + syslog_enabled=false
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#INCLUDE_SYSLOG_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + configure_cloud_logging_base_url
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: + cloud_logging_base_url=
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ is_tpc
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: +++ get_universe_domain
<13>Apr 27 18:07:35 dataproc-startup-script[1253]: <13>Apr 27 18:07:35 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++++ gcloud config get core/universe_domain
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: +++ local -r universe_domain=googleapis.com
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: +++ echo googleapis.com
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ [[ googleapis.com == \g\o\o\g\l\e\a\p\i\s\.\c\o\m ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: ++ return 0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: + [[ -n '' ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#CLOUD_LOGGING_BASE_URL_PLACEHOLDER## /etc/ucp/logging/configs/fluentbit.conf
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-fluentbit-ucp[2853]: + sed -i -e s#CLOUD_LOGGING_BASE_URL_PLACEHOLDER## /etc/ucp/logging/configs/optional_logging/dataproc-syslog.conf
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/fluentbit-ucp.pre-activate
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: Running task: hdfs.pre-activate
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hdfs.sh"; exit 1; }
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-hdfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-hdfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-hdfs[3081]'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + readonly HDFS_ADMIN=hdfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_ADMIN=hdfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + readonly HDFS_SITE_XML=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_SITE_XML=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + readonly CLUSTER_PROPS_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + CLUSTER_PROPS_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export HDFS_NAME_DIR=/hadoop/dfs/name
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_NAME_DIR=/hadoop/dfs/name
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export HDFS_SECONDARY_NAME_DIR=/hadoop/dfs/namesecondary
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_SECONDARY_NAME_DIR=/hadoop/dfs/namesecondary
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_cluster_name
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_CLUSTER_NAME attributes/dataproc-cluster-name
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + CLUSTER_NAME=cluster-dip-01
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export CLUSTER_NAME
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_master
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_master_additional
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + NUM_MASTERS=1
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_worker_count
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_WORKER_COUNT attributes/dataproc-worker-count
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + NUM_WORKERS=3
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + DATANODE_PACKAGES=('hadoop-hdfs-datanode')
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + THIRD_MASTER_OPTIONAL_PACKAGES=('hadoop-hdfs-namenode' 'hadoop-hdfs-zkfc')
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + (( i = 0 ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + (( i < 1 ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + declare MASTER_HOSTNAME_0=cluster-dip-01-m
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export MASTER_HOSTNAME_0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + (( i++ ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + (( i < 1 ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ is_component_selected kerberos
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ local -r component=kerberos
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ local activated_components
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ get_components_to_activate
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ echo false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + KERBEROS_ENABLED=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export ENABLE_HDFS_PERMISSIONS=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + ENABLE_HDFS_PERMISSIONS=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + DATA_DIRS_ARRAY=($(get_data_dirs))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ get_data_dirs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ local -a mount_points
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ mapfile -t mount_points
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ find '/mnt/[0-9]*/' -maxdepth 0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: find: /mnt/[0-9]*/: No such file or directory
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: +++ true
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ (( 0 ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ echo /
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ return
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_DIRS=/hadoop/dfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_DIRS_ARRAY=(${HDFS_DIRS})
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_DATA_DIRS=/hadoop/dfs/data
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_DATA_DIRS_ARRAY=(${HDFS_DATA_DIRS})
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + mkdir -p /hadoop/dfs /hadoop/dfs/data
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + chown -L -R hdfs:hadoop /hadoop/dfs /hadoop/dfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + chmod -R 700 /hadoop/dfs
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ free -m
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ awk '/^Mem:/{print $2}'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + TOTAL_MEM=7949
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ python -c 'print(int(7949 * 0.4 / 2))'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + NAMENODE_MEM_MB=1589
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + SECONDARYNAMENODE_MEM_MB=1589
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local reenable_x=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ -o xtrace ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + case ${compare_versions_result} in
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + return 0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + GC_LOG_OPTS='-Xlog:gc*:stdout:time,level,tags'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ grep GC_OPTS /tmp/cluster/properties/hadoop-env.sh
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ cut -d= -f2
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ head -n1
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ :
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + USER_SUPPLIED_GC_OPTS=
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ -z '' ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local reenable_x=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ -o xtrace ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + case ${compare_versions_result} in
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + return 1
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + GC_OPTS=-XX:+UseConcMarkSweepGC
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + GC_JDK17_OPTS=
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local reenable_x=false
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ -o xtrace ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + set +x
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + case ${compare_versions_result} in
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + return 1
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + cat
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + export HDFS_DATA_DIRS=/hadoop/dfs/data
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_DATA_DIRS=/hadoop/dfs/data
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + readonly HDFS_TEMPLATE=hdfs-template.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_TEMPLATE=hdfs-template.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/hdfs-site.xml --source_configuration_file hdfs-template.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + (( NUM_WORKERS == 0 ))
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + readonly HDFS_SIMPLIFICATION_MIXINS=hdfs-simplification-mixins.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + HDFS_SIMPLIFICATION_MIXINS=hdfs-simplification-mixins.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/hdfs-site.xml --source_configuration_file /usr/local/share/google/dataproc/bdutil/conf/hdfs-simplification-mixins.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_in_xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local host_name
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local domain
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ dnsdomainname
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + domain=c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + host_name=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.namenode.http-address cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.namenode.http-address
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.http-address
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:36.821211 140457299890880 xml_config_commands.py:181] Property value is: "cluster-dip-01-m:50070"
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + prop_value=cluster-dip-01-m:50070
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ cluster-dip-01-m:50070 != \N\o\n\e ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + loginfo 'Reading dfs.namenode.http-address in /etc/hadoop/conf/hdfs-site.xml'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + echo 'Reading dfs.namenode.http-address in /etc/hadoop/conf/hdfs-site.xml'
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: Reading dfs.namenode.http-address in /etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ sed -e s/0.0.0.0/cluster-dip-01-m.c.euphoric-coral-451717-v8.internal/g
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ echo cluster-dip-01-m:50070
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + updated_value=cluster-dip-01-m:50070
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ cluster-dip-01-m:50070 != \c\l\u\s\t\e\r\-\d\i\p\-\0\1\-\m\:\5\0\0\7\0 ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.namenode.https-address cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.namenode.https-address
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.https-address
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:36.918246 140454478009024 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.namenode.secondary.http-address cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.namenode.secondary.http-address
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:36 dataproc-startup-script[1253]: <13>Apr 27 18:07:36 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.secondary.http-address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.013492 140090940805824 xml_config_commands.py:181] Property value is: "cluster-dip-01-m:50090"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=cluster-dip-01-m:50090
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ cluster-dip-01-m:50090 != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + loginfo 'Reading dfs.namenode.secondary.http-address in /etc/hadoop/conf/hdfs-site.xml'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + echo 'Reading dfs.namenode.secondary.http-address in /etc/hadoop/conf/hdfs-site.xml'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: Reading dfs.namenode.secondary.http-address in /etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ echo cluster-dip-01-m:50090
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ sed -e s/0.0.0.0/cluster-dip-01-m.c.euphoric-coral-451717-v8.internal/g
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + updated_value=cluster-dip-01-m:50090
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ cluster-dip-01-m:50090 != \c\l\u\s\t\e\r\-\d\i\p\-\0\1\-\m\:\5\0\0\9\0 ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.namenode.secondary.https-address cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.namenode.secondary.https-address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.secondary.https-address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.111559 140363270193856 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ hostname -f
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + host_name=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.datanode.address cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.datanode.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.datanode.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.208706 140056252662464 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.datanode.http.address cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.datanode.http.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.datanode.http.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.304109 140013666001600 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.datanode.https.address cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.datanode.https.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.datanode.https.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.399530 139713006654144 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hostname_for_property /etc/hadoop/conf/hdfs-site.xml dfs.datanode.ipc.address cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local xml_file=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_name=dfs.datanode.ipc.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local host_name=cluster-dip-01-w-2.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local updated_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local prop_value
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ bdconfig get_property_value --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.datanode.ipc.address
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: I0427 18:07:37.495784 139631909429952 xml_config_commands.py:181] Property value is: "None"
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + prop_value=None
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ None != \N\o\n\e ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + update_hdfs_param_values
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.replication.work.multiplier.per.iteration --value 20 --clobber
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.replication.max-streams --value 20 --clobber
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.namenode.replication.max-streams-hard-limit --value 40 --clobber
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + merge_xml_properties /tmp/cluster/properties/hdfs.xml /etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local src=/tmp/cluster/properties/hdfs.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + local dest=/etc/hadoop/conf/hdfs-site.xml
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + [[ ! -f /tmp/cluster/properties/hdfs.xml ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + bdconfig merge_configurations --configuration_file /etc/hadoop/conf/hdfs-site.xml --source_configuration_file /tmp/cluster/properties/hdfs.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + loginfo 'Merged /tmp/cluster/properties/hdfs.xml.'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: + echo 'Merged /tmp/cluster/properties/hdfs.xml.'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: Merged /tmp/cluster/properties/hdfs.xml.
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ create_or_validate_include_file_path
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local include_path
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: +++ get_include_file_path
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: +++ local include_path
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++++ /usr/share/google/get_metadata_value attributes/dataproc-include-file-location
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: +++ include_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: +++ [[ -z gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: +++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ include_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ [[ gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include == gs://* ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ loginfo 'Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ echo 'Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include'
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: Checking if include membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ retry_constant_custom 10 3 gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local -r max_retry_time=10
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local -r retry_delay=3
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ cmd=('gcs_file_exists' 'gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include')
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local -r cmd
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local -r max_retries=3
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ local reenable_x=false
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:37 dataproc-startup-script[1253]: <13>Apr 27 18:07:37 dataproc-pre-activate-component-hdfs[3081]: About to run 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include' with retries...
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include' succeeded after 1 execution(s).
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ return 0
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: + INCLUDE_PATH=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ create_or_validate_exclude_file_path
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local exclude_path
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: +++ get_exclude_file_path
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: +++ local exclude_path
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++++ /usr/share/google/get_metadata_value attributes/dataproc-exclude-file-location
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: +++ exclude_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: +++ [[ -z gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml ]]
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: +++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ exclude_path=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ [[ gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml == gs://* ]]
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ loginfo 'Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml'
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ echo 'Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml'
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: Checking if exclude membership files exist in GCS: gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ retry_constant_custom 10 3 gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local -r max_retry_time=10
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local -r retry_delay=3
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ cmd=('gcs_file_exists' 'gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml')
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local -r cmd
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local -r max_retries=3
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ local reenable_x=false
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:39 dataproc-startup-script[1253]: <13>Apr 27 18:07:39 dataproc-pre-activate-component-hdfs[3081]: About to run 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml' with retries...
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: 'gcs_file_exists gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml' succeeded after 1 execution(s).
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ return 0
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ echo gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + EXCLUDE_PATH=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.hosts --value gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_include --clobber
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + bdconfig set_property --configuration_file /etc/hadoop/conf/hdfs-site.xml --name dfs.hosts.exclude --value gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/nodes_exclude.xml --clobber
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_datanode_enabled
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_DATANODE_ENABLED attributes/dataproc-datanode-enabled
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + [[ true != \t\r\u\e ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ get_metadata_role
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: ++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hdfs[3081]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/hdfs.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: Running task: hive-metastore.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-metastore.sh"; exit 1; }
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_metadata_master
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_metadata_master_additional
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ NUM_MASTERS=1
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_metadata_role
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ ROLE=Worker
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ [[ 1 -gt 1 ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ CLUSTER_MASTER_METASTORE_URIS=thrift://cluster-dip-01-m:9083
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + set -x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-hive-metastore
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-hive-metastore
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-hive-metastore[3510]'
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + CLUSTER_PROPERTIES_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name hive.metastore.uris --value thrift://cluster-dip-01-m:9083 --clobber
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + is_component_selected hdfs
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + local -r component=hdfs
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + local activated_components
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ get_components_to_activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *hdfs* ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ get_property_in_xml /etc/hive/conf/hive-site.xml hive.metastore.warehouse.dir
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: ++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + HIVE_WAREHOUSE_DIR=
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + [[ '' == \g\s\:\/\/* ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + METADATASTORE_JDBC_URI=jdbc:mysql://cluster-dip-01-m/metastore
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-hive-metastore[3510]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name javax.jdo.option.ConnectionURL --value jdbc:mysql://cluster-dip-01-m/metastore --clobber
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/hive-metastore.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: Running task: mysql.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/mysql.sh"; exit 1; }
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ is_version_at_least 2.2 2.2
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ local reenable_x=false
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ case ${compare_versions_result} in
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ return 0
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ MYSQL_VERSION=8.0
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ MYSQL_EL_VERSION=8
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/os/debian/components/pre-activate/mysql.sh
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + set -x
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-mysql
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-mysql
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-mysql[3593]'
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/mysql.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-mysql[3593]: + [[ cluster-dip-01-w-2 != \c\l\u\s\t\e\r\-\d\i\p\-\0\1\-\m ]]
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: Running task: tez.pre-activate
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/tez.sh"; exit 1; }
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-mysql[3593]: + echo 'Skip running MySQL on cluster-dip-01-w-2'
<13>Apr 27 18:07:40 dataproc-startup-script[1253]: <13>Apr 27 18:07:40 dataproc-pre-activate-component-mysql[3593]: Skip running MySQL on cluster-dip-01-w-2
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-tez
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-tez
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-tez[3603]'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ ls /usr/lib/tez/tez-ui-0.10.2.war
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + readonly TEZ_UI_WAR=/usr/lib/tez/tez-ui-0.10.2.war
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + TEZ_UI_WAR=/usr/lib/tez/tez-ui-0.10.2.war
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + pre_activate_tez
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + configure_ui_war
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local tmp_dir
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ mktemp -d
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + tmp_dir=/tmp/tmp.Q1ojH9MsKr
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + unzip -q /usr/lib/tez/tez-ui-0.10.2.war -d /tmp/tmp.Q1ojH9MsKr
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local -r tez_configs=/tmp/tmp.Q1ojH9MsKr/config/configs.env
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local -r tez_ui_js=/tmp/tmp.Q1ojH9MsKr/assets/tez-ui.js
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local ats_v2_port=8192
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + is_component_selected kerberos
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local -r component=kerberos
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local activated_components
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_components_to_activate
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local ats_v2_enabled=false
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_dataproc_property yarn.atsv2.bigtable.instance
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -n '' ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -f /tmp/tmp.Q1ojH9MsKr/config/configs.env ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -f /tmp/tmp.Q1ojH9MsKr/assets/tez-ui.js ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + sed -i 's#"timeline":"localhost:8188"#"timeline":"cluster-dip-01-w-2:8188"#' /tmp/tmp.Q1ojH9MsKr/assets/tez-ui.js
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + sed -i 's#"timelineV2":"localhost:8192"#"timelineV2":"cluster-dip-01-w-2:8192"#' /tmp/tmp.Q1ojH9MsKr/assets/tez-ui.js
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + sed -i 's#"rm":"localhost:8088"#"rm":"cluster-dip-01-w-2:8088"#' /tmp/tmp.Q1ojH9MsKr/assets/tez-ui.js
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + is_component_selected knox
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local -r component=knox
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local activated_components
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_components_to_activate
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *knox* ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local cluster_ui_hostname
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ sed 's/\\:/:/'
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_dataproc_property dataproc.proxy.public.hostname
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + cluster_ui_hostname=https://hai26gzvrngzjp6hwhycsnr4ly-dot-us-east1.dataproc.googleusercontent.com
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + cat
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + cd /tmp/tmp.Q1ojH9MsKr
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + zip -q /usr/lib/tez/tez-ui-0.10.2.war -r ./META-INF ./WEB-INF ./assets ./config ./fonts ./index.html
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + cd ..
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + rm -rf /tmp/tmp.Q1ojH9MsKr
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ stat /usr/lib/tez/tez-common-0.10.2.jar --format=%Y
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + touch -d @1579705815 /usr/lib/tez/tez-ui-0.10.2.war
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + configure_yarn_for_tez
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.ui-names --value tez --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.ui-on-disk-path.tez --value /usr/lib/tez/tez-ui-0.10.2.war --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/hadoop/conf/yarn-site.xml --name yarn.timeline-service.ui-web-path.tez --value /tez-ui --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + configure_tez
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local history_logging_service_class=ATSHistoryLoggingService
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ get_dataproc_property yarn.atsv2.bigtable.instance
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: ++ set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -n '' ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/tez/conf/tez-site.xml --name tez.history.logging.service.class --value org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/tez/conf/tez-site.xml --name tez.tez-ui.history-url.base --value http://cluster-dip-01-m:8188/tez-ui/ --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig set_property --configuration_file /etc/tez/conf/tez-site.xml --name tez.am.node-blacklisting.enabled --value false --clobber
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + configure_tez_for_jdk17
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local reenable_x=false
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -o xtrace ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + set +x
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + case ${compare_versions_result} in
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + return 1
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + return
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + merge_user_properties
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ -f /etc/tez/conf/tez-site.xml ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + merge_xml_properties /tmp/cluster/properties/tez.xml /etc/tez/conf/tez-site.xml
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local src=/tmp/cluster/properties/tez.xml
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + local dest=/etc/tez/conf/tez-site.xml
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + [[ ! -f /tmp/cluster/properties/tez.xml ]]
<13>Apr 27 18:07:41 dataproc-startup-script[1253]: <13>Apr 27 18:07:41 dataproc-pre-activate-component-tez[3603]: + bdconfig merge_configurations --configuration_file /etc/tez/conf/tez-site.xml --source_configuration_file /tmp/cluster/properties/tez.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-tez[3603]: + loginfo 'Merged /tmp/cluster/properties/tez.xml.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-tez[3603]: + echo 'Merged /tmp/cluster/properties/tez.xml.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/tez.pre-activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-tez[3603]: Merged /tmp/cluster/properties/tez.xml.
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: Running task: hive-server2.pre-activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/hive-server2.sh"; exit 1; }
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-hive-server2
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-hive-server2
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-hive-server2[3674]'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + CLUSTER_PROPERTIES_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_metadata_bucket
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_dataproc_metadata DATAPROC_METADATA_BUCKET attributes/dataproc-bucket
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + CONFIGBUCKET=dataproc-staging-us-east1-679657336577-kutp8kah
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_metadata_cluster_uuid
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_dataproc_metadata DATAPROC_METADATA_CLUSTER_UUID attributes/dataproc-cluster-uuid
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + CLUSTER_UUID=0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_metadata_master
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_metadata_master_additional
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + NUM_MASTERS=1
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ 1 -gt 1 ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name hive.user.install.directory --value '${hadoop.tmp.dir}/hive/user-install-dir' --clobber
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local reenable_x=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ -o xtrace ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + case ${compare_versions_result} in
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + return 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + set_property_hive_site hive.exec.input.listing.max.threads 20
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r name=hive.exec.input.listing.max.threads
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r value=20
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + set_property_in_xml /etc/hive/conf/hive-site.xml hive.exec.input.listing.max.threads 20
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r xml_file=/etc/hive/conf/hive-site.xml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r name=hive.exec.input.listing.max.threads
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r value=20
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r mode=overwrite
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r delimiter=,
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local skip=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local old_value
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local new_value
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + new_value=20
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name hive.exec.input.listing.max.threads --value 20 --create_if_absent --clobber
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + set_property_hive_site hive.fetch.task.conversion minimal
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r name=hive.fetch.task.conversion
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r value=minimal
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + set_property_in_xml /etc/hive/conf/hive-site.xml hive.fetch.task.conversion minimal
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r xml_file=/etc/hive/conf/hive-site.xml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r name=hive.fetch.task.conversion
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r value=minimal
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r mode=overwrite
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r delimiter=,
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local skip=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local old_value
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local new_value
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ overwrite == \o\v\e\r\w\r\i\t\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + new_value=minimal
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ false == \f\a\l\s\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name hive.fetch.task.conversion --value minimal --create_if_absent --clobber
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + is_component_selected trino
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r component=trino
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local activated_components
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_components_to_activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *trino* ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + merge_xml_properties /tmp/cluster/properties/hive.xml /etc/hive/conf/hive-site.xml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local src=/tmp/cluster/properties/hive.xml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local dest=/etc/hive/conf/hive-site.xml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ ! -f /tmp/cluster/properties/hive.xml ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + bdconfig merge_configurations --configuration_file /etc/hive/conf/hive-site.xml --source_configuration_file /tmp/cluster/properties/hive.xml --resolve_environment_variables --create_if_absent --clobber
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + loginfo 'Merged /tmp/cluster/properties/hive.xml.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + echo 'Merged /tmp/cluster/properties/hive.xml.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: Merged /tmp/cluster/properties/hive.xml.
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + merge_java_properties /tmp/cluster/properties/hive-log4j2.properties /etc/hive/conf/hive-log4j2.properties
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r src=/tmp/cluster/properties/hive-log4j2.properties
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r dest=/etc/hive/conf/hive-log4j2.properties
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + [[ ! -f /tmp/cluster/properties/hive-log4j2.properties ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + cat /tmp/cluster/properties/hive-log4j2.properties
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + loginfo 'Merged /tmp/cluster/properties/hive-log4j2.properties.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: + echo 'Merged /tmp/cluster/properties/hive-log4j2.properties.'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-hive-server2[3674]: Merged /tmp/cluster/properties/hive-log4j2.properties.
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/hive-server2.pre-activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: Running task: otel-ucp.pre-activate
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/otel-ucp.sh"; exit 1; }
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: 60
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: 300
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: 1440
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-otel-ucp
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-otel-ucp
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-otel-ucp[3796]'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_dataproc_property dataproc.observability.containerised.legacy.agents.enable
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + CONTAINERISED_AGENTS_ENABLED=
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_metadata_project_number
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_dataproc_metadata DATAPROC_METADATA_PROJECT_NUMBER ../project/numeric-project-id
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + PROJECT_NUMBER=679657336577
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + readonly OTEL_S8S_DIR=/usr/local/share/google/dataproc/bdutil/conf/otel
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + OTEL_S8S_DIR=/usr/local/share/google/dataproc/bdutil/conf/otel
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + is_any_metric_source_enabled
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local stack_driver_monitoring_enabled
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_dataproc_property dataproc.monitoring.stackdriver.enable
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + stack_driver_monitoring_enabled=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local metric_sources_enabled_array
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + get_enabled_metric_sources_array metric_sources_enabled_array
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local -n ms_array=metric_sources_enabled_array
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local metric_sources_enabled_delimited_by_comma
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_dataproc_property dataproc.monitoring.metric.sources
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + metric_sources_enabled_delimited_by_comma=
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + use_ucp_observability_agents
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ standard != \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + is_containerised_legacy_agents_supported
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + is_version_at_least 2.2 2.2
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local reenable_x=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ -o xtrace ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + case ${compare_versions_result} in
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + return 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + return 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + is_legacy_containerized_agents_enabled
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ get_dataproc_property_or_default dataproc.observability.containerised.legacy.agents.enable false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ set +x
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local -r legacy_containerised_agents_enabled=false
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + return 0
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + metric_sources_enabled_delimited_by_comma=
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + ms_array=(${metric_sources_enabled_delimited_by_comma//,/ })
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + [[ 0 -gt 0 ]]
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + return 1
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + cp /usr/local/share/google/dataproc/bdutil/monitoring_plugin_generator/dataproc_otel_base.yaml /etc/ucp/monitoring/configs/otel_base_config.yaml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + cp /usr/local/share/google/dataproc/bdutil/conf/otel_spark_default_metrics.yaml /etc/ucp/monitoring/configs/spark_default_metrics.yaml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + cp /usr/local/share/google/dataproc/bdutil/conf/otel_gcs_connector_metrics.yaml /etc/ucp/monitoring/configs/gcs_connector_metrics.yaml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + configure_ucp_monitoring_agent
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + otel_args=()
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local otel_args
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ sort
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: ++ find /etc/ucp/monitoring/configs/ -type f -name '*.yaml'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local -r 'config_files=/etc/ucp/monitoring/configs/gcs_connector_metrics.yaml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: /etc/ucp/monitoring/configs/otel_base_config.yaml
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: /etc/ucp/monitoring/configs/spark_default_metrics.yaml'
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + for yaml_file in $config_files
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + otel_args+=("--config ${yaml_file}")
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + for yaml_file in $config_files
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + otel_args+=("--config ${yaml_file}")
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + for yaml_file in $config_files
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + otel_args+=("--config ${yaml_file}")
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + local -r monitoring_agent_service_file=/etc/systemd/system/otel-metrics-agent.service
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + cat
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + systemctl daemon-reload
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: + systemctl enable otel-metrics-agent
<13>Apr 27 18:07:42 dataproc-startup-script[1253]: <13>Apr 27 18:07:42 dataproc-pre-activate-component-otel-ucp[3796]: Created symlink /etc/systemd/system/multi-user.target.wants/otel-metrics-agent.service  /etc/systemd/system/otel-metrics-agent.service.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/otel-ucp.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running task: pig.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/pig.sh"; exit 1; }
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-pig
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-pig
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-pig[3884]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + merge_user_properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + merge_java_properties /tmp/cluster/properties/pig.properties /etc/pig/conf/pig.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r src=/tmp/cluster/properties/pig.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r dest=/etc/pig/conf/pig.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + [[ ! -f /tmp/cluster/properties/pig.properties ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + cat /tmp/cluster/properties/pig.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + loginfo 'Merged /tmp/cluster/properties/pig.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + echo 'Merged /tmp/cluster/properties/pig.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: Merged /tmp/cluster/properties/pig.properties.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + merge_java_properties /tmp/cluster/properties/pig-log4j.properties /etc/pig/conf/log4j.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r src=/tmp/cluster/properties/pig-log4j.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r dest=/etc/pig/conf/log4j.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + [[ ! -f /tmp/cluster/properties/pig-log4j.properties ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + cat /tmp/cluster/properties/pig-log4j.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + loginfo 'Merged /tmp/cluster/properties/pig-log4j.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: + echo 'Merged /tmp/cluster/properties/pig-log4j.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/pig.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-pig[3884]: Merged /tmp/cluster/properties/pig-log4j.properties.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running task: spark.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh"; exit 1; }
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_metadata_master
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_metadata_master_additional
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ NUM_MASTERS=1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_metadata_role
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: +++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ ROLE=Worker
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ [[ 1 -gt 1 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ CLUSTER_MASTER_METASTORE_URIS=thrift://cluster-dip-01-m:9083
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ dirname /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/components/pre-activate/../shared/nvidia-drivers.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ dirname /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/components/pre-activate/../shared/spark.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_HOME=/usr/lib/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_HOME=/usr/lib/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_JARS_DIR=/usr/lib/spark/jars
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_JARS_DIR=/usr/lib/spark/jars
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ [[ 2.2 =~ ^2\.[01]$ ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONNECTOR_DIR=/usr/lib/spark/connector
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONNECTOR_DIR=/usr/lib/spark/connector
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONF_DIR=/etc/spark/conf
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONF_DIR=/etc/spark/conf
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_AUTH_SECRET_FILE=/tmp/cluster/spark.auth.secret
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_AUTH_SECRET_FILE=/tmp/cluster/spark.auth.secret
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export LINEAGE_LIB_DIR=/usr/local/share/google/dataproc/lineage
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ LINEAGE_LIB_DIR=/usr/local/share/google/dataproc/lineage
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ CLUSTER_PROPERTIES_DIR=/tmp/cluster/properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_DATA_DIR=/hadoop/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_DATA_DIR=/hadoop/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_LOG_DIR=/var/log/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_LOG_DIR=/var/log/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_TMP_DIR=/hadoop/spark/tmp
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_TMP_DIR=/hadoop/spark/tmp
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_WORK_DIR=/hadoop/spark/work
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_WORK_DIR=/hadoop/spark/work
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONNECT_PORT=15001
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONNECT_PORT=15001
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONNECT_PROXY_PORT=8443
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONNECT_PROXY_PORT=8443
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONNECT_SYSTEMD_UNIT_PATH=/usr/lib/systemd/system/spark-connect.service
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONNECT_SYSTEMD_UNIT_PATH=/usr/lib/systemd/system/spark-connect.service
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_CONNECT_PROXY_SYSTEMD_UNIT_PATH=/usr/lib/systemd/system/spark-connect-proxy.service
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_CONNECT_PROXY_SYSTEMD_UNIT_PATH=/usr/lib/systemd/system/spark-connect-proxy.service
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export SPARK_NATIVE_HOME_DIR=/usr/lib/spark/native
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ SPARK_NATIVE_HOME_DIR=/usr/lib/spark/native
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ dirname /usr/local/share/google/dataproc/bdutil/components/pre-activate/spark.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/bdutil/components/pre-activate/../shared/delta.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_HOME=/usr/lib/delta/lib
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_HOME=/usr/lib/delta/lib
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_SPARK_JAR=delta-spark_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_SPARK_JAR=delta-spark_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_STORAGE_JAR=delta-storage-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_STORAGE_JAR=delta-storage-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_HIVE_JAR=delta-hive-assembly_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_HIVE_JAR=delta-hive-assembly_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_SPARK_JAR_PATH=/usr/lib/delta/lib/delta-spark_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_SPARK_JAR_PATH=/usr/lib/delta/lib/delta-spark_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_STORAGE_JAR_PATH=/usr/lib/delta/lib/delta-storage-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_STORAGE_JAR_PATH=/usr/lib/delta/lib/delta-storage-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ export DELTA_HIVE_JAR_PATH=/usr/lib/delta/lib/delta-hive-assembly_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DELTA_HIVE_JAR_PATH=/usr/lib/delta/lib/delta-hive-assembly_2.12-3.2.0.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + source /usr/local/share/google/dataproc/dataproc_env.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ CLUSTER_NAME=cluster-dip-01
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ CLUSTER_UUID=0b63cfa9-1f8a-481e-87c8-a0cf661f3625
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ CONFIGBUCKET=dataproc-staging-us-east1-679657336577-kutp8kah
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ TEMP_BUCKET=dataproc-temp-us-east1-679657336577-juievcnm
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ HCFS_ROOT_URI=hdfs://cluster-dip-01-m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ MASTER_HOSTNAME_0=cluster-dip-01-m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ DATAPROC_MASTER_FQDN=cluster-dip-01-m.c.euphoric-coral-451717-v8.internal
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ MASTER_HOSTNAMES=(cluster-dip-01-m)
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ NUM_MASTERS=1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ NUM_WORKERS=3
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ PROJECT=euphoric-coral-451717-v8
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ ROLE=Worker
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set -x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-spark[4005]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + readonly SPARK_STANDALONE_LOCAL_DATA_DIR=/hadoop/spark/local-dir
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + SPARK_STANDALONE_LOCAL_DATA_DIR=/hadoop/spark/local-dir
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + pre_activate_spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + update_bq_connector
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local connector_version
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_metadata_spark_bq_connector_version
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_metadata DATAPROC_METADATA_SPARK_BQ_CONNECTOR_VERSION attributes/SPARK_BQ_CONNECTOR_VERSION
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + connector_version=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local connector_url
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_metadata_spark_bq_connector_url
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_metadata DATAPROC_METADATA_SPARK_BQ_CONNECTOR_URL attributes/SPARK_BQ_CONNECTOR_URL
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + connector_url=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local jar_name
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -z '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -n '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -n '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + init_local_dirs_common
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + mkdir -p /hadoop/spark/tmp /hadoop/spark/work /var/log/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + chown spark:spark -R /hadoop/spark /var/log/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + chmod 1777 -R /hadoop/spark /var/log/spark
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + ln -sf /hadoop/spark/work /usr/lib/spark/work
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_env_common
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_event_log_dir
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local persist_history_to_gcs
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property_or_default job.history.to-gcs.enabled false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + persist_history_to_gcs=true
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local event_log_dir=hdfs://cluster-dip-01-m/user/spark/eventlog
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + loginfo 'Enabling persisting Spark job history files to GCS.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo 'Enabling persisting Spark job history files to GCS.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: Enabling persisting Spark job history files to GCS.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -n dataproc-temp-us-east1-679657336577-juievcnm ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local gcs_history_dir_path=0b63cfa9-1f8a-481e-87c8-a0cf661f3625/spark-job-history
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + event_log_dir=gs://dataproc-temp-us-east1-679657336577-juievcnm/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/spark-job-history
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_arrow
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ 2.2 == \1\.\5 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_env_yarn
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_defaults_yarn
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_component_selected hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r component=hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local activated_components
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_components_to_activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *hive-server2* ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local enable_docker_yarn
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property_or_default yarn.docker.enable ''
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + enable_docker_yarn=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -z '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property_or_default docker.yarn.enable ''
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + enable_docker_yarn=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_efm
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local spark_efm_property
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property efm.spark.shuffle
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + spark_efm_property=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ '' == \p\r\i\m\a\r\y\-\w\o\r\k\e\r ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_component_selected kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r component=kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local activated_components
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_components_to_activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + merge_user_properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + merge_java_properties /tmp/cluster/properties/spark.properties /etc/spark/conf/spark-defaults.conf
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r src=/tmp/cluster/properties/spark.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r dest=/etc/spark/conf/spark-defaults.conf
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ ! -f /tmp/cluster/properties/spark.properties ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat /tmp/cluster/properties/spark.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + loginfo 'Merged /tmp/cluster/properties/spark.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo 'Merged /tmp/cluster/properties/spark.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: Merged /tmp/cluster/properties/spark.properties.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + merge_sh_env_vars /tmp/cluster/properties/spark-env.sh /etc/spark/conf/spark-env.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local src=/tmp/cluster/properties/spark-env.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local dest=/etc/spark/conf/spark-env.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ ! -f /tmp/cluster/properties/spark-env.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat /tmp/cluster/properties/spark-env.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + loginfo 'Merged /tmp/cluster/properties/spark-env.sh.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo 'Merged /tmp/cluster/properties/spark-env.sh.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: Merged /tmp/cluster/properties/spark-env.sh.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 2.1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + merge_java_properties /tmp/cluster/properties/spark-log4j2.properties /etc/spark/conf/log4j2.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r src=/tmp/cluster/properties/spark-log4j2.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r dest=/etc/spark/conf/log4j2.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r 'header=\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ ! -f /tmp/cluster/properties/spark-log4j2.properties ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo -e '\n# User-supplied properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat /tmp/cluster/properties/spark-log4j2.properties
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + loginfo 'Merged /tmp/cluster/properties/spark-log4j2.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + echo 'Merged /tmp/cluster/properties/spark-log4j2.properties.'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: Merged /tmp/cluster/properties/spark-log4j2.properties.
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_lineage
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ ! -v OPENLINEAGE_VERSION ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local lineage_enabled=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_rm_image
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_metadata_dataproc_lineage_enabled
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_metadata DATAPROC_METADATA_LINEAGE_ENABLED attributes/DATAPROC_LINEAGE_ENABLED
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + lineage_enabled=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property_or_default dataproc.lineage.enabled ''
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + lineage_enabled=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + configure_broadcast_join 0.0075 200
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r fraction=0.0075
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local -r max_mb=200
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local user_broadcast_join_threshold_mb
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_java_property /etc/spark/conf/spark-defaults.conf spark.sql.autoBroadcastJoinThreshold
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + user_broadcast_join_threshold_mb=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -n '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local spark_executor_memory
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_java_property /etc/spark/conf/spark-defaults.conf spark.executor.memory
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + spark_executor_memory=2893m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local spark_executor_memory_bytes
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_size_in_bytes 2893m
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ local size=2893M
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ size=2893M
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ size=2893M
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ numfmt --from=iec 2893M
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + spark_executor_memory_bytes=3033530368
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local broadcast_join_threshold_mb
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ python -c 'print(min(max(int(3033530368 * 0.0075 / 1024 / 1024), 10), 200))'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + broadcast_join_threshold_mb=21
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cat
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_rm_image
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\r\a\y ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local cohort
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ get_dataproc_property internal.cohort
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + cohort=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + is_version_at_least 2.2 3.0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + local reenable_x=false
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -o xtrace ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + case ${compare_versions_result} in
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + return 1
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-spark[4005]: + [[ -n '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/spark.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running task: yarn.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: bash -e /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh 2.2 || { echo "Error: /usr/local/share/google/dataproc/bdutil/components/pre-activate/yarn.sh"; exit 1; }
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-activate-component-yarn
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-activate-component-yarn
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-activate-component-yarn[4219]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ get_dataproc_property yarn.atsv2.bigtable.instance
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + readonly ATSV2_BIGTABLE_RESOURCE=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + ATSV2_BIGTABLE_RESOURCE=
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + [[ -n '' ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + rm -Rf /usr/local/share/google/dataproc/lib/bigtable-hbase-2.x-hadoop-1.26.2.jar
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + is_component_selected kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + local -r component=kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + local activated_components
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ get_components_to_activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ set +x
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-activate-component-yarn[4219]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: touch /tmp/dataproc/sentinel/yarn.pre-activate
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'All pre-activate scripts done'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: All pre-activate scripts done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling unselected components'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling unselected components'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling unselected components
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_components delta docker-ce dpms-proxy flink google-fluentd-container hive-metastore hive-server2 hive-webhcat-server hudi iceberg jupyter jupyter-kernel-gateway kerberos knox proxy-agent ranger rubix solr-server stackdriver-agent-container trino zeppelin zookeeper-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + components=('delta' 'docker-ce' 'dpms-proxy' 'flink' 'google-fluentd-container' 'hive-metastore' 'hive-server2' 'hive-webhcat-server' 'hudi' 'iceberg' 'jupyter' 'jupyter-kernel-gateway' 'kerberos' 'knox' 'proxy-agent' 'ranger' 'rubix' 'solr-server' 'stackdriver-agent-container' 'trino' 'zeppelin' 'zookeeper-server')
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local components
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + mkdir -p /tmp/dataproc/components/pre-uninstall
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component delta'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component delta'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component delta
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component delta
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=delta
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/delta.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/delta.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/delta.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/delta.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/delta.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/delta.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-delta
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-delta
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-delta[4301]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/delta.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component docker-ce'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component docker-ce'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/docker-ce.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/docker-ce.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-docker-ce[4308]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/docker-ce.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-docker-ce[4308]: + mark_packages_to_uninstall docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-docker-ce[4308]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-docker-ce[4308]: + touch /tmp/dataproc/uninstall/docker-ce
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component dpms-proxy'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component dpms-proxy'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component dpms-proxy
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component dpms-proxy
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=dpms-proxy
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/dpms-proxy.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/dpms-proxy.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Component dpms-proxy doesn'\''t have a pre-uninstall script'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Component dpms-proxy doesn't have a pre-uninstall script
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component flink'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component flink'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/flink.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/flink.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/flink.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/flink.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/flink.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/flink.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-flink[4316]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/flink.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-flink[4316]: + mark_packages_to_uninstall flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-flink[4316]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-flink[4316]: + touch /tmp/dataproc/uninstall/flink
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component google-fluentd-container'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component google-fluentd-container'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component google-fluentd-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component google-fluentd-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=google-fluentd-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/google-fluentd-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/google-fluentd-container.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/google-fluentd-container.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/google-fluentd-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/google-fluentd-container.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/google-fluentd-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/google-fluentd-container.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component hive-metastore'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component hive-metastore'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-metastore.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-metastore.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-metastore.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-metastore.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-metastore.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-metastore.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-hive-metastore[4327]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-metastore.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-metastore[4327]: + mark_packages_to_uninstall hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-metastore[4327]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-metastore[4327]: + touch /tmp/dataproc/uninstall/hive-metastore
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component hive-server2'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component hive-server2'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-server2.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-server2.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-server2.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-server2.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-server2.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-server2.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-hive-server2[4335]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-server2.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-server2[4335]: + mark_packages_to_uninstall hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-server2[4335]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-server2[4335]: + touch /tmp/dataproc/uninstall/hive-server2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component hive-webhcat-server'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component hive-webhcat-server'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-webhcat-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-webhcat-server.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-webhcat-server.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-webhcat-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-webhcat-server.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hive-webhcat-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-hive-webhcat-server[4400]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/hive-webhcat-server.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-webhcat-server[4400]: + mark_packages_to_uninstall hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-webhcat-server[4400]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-hive-webhcat-server[4400]: + touch /tmp/dataproc/uninstall/hive-webhcat-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component hudi'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component hudi'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component hudi
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component hudi
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=hudi
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hudi.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/hudi.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Component hudi doesn'\''t have a pre-uninstall script'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Component hudi doesn't have a pre-uninstall script
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component iceberg'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component iceberg'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/iceberg.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/iceberg.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/iceberg.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/iceberg.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/iceberg.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/iceberg.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-iceberg[4465]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/iceberg.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-iceberg[4465]: + mark_packages_to_uninstall iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-iceberg[4465]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-iceberg[4465]: + touch /tmp/dataproc/uninstall/iceberg
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component jupyter'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component jupyter'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component jupyter
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component jupyter
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=jupyter
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/jupyter.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/jupyter.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Component jupyter doesn'\''t have a pre-uninstall script'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Component jupyter doesn't have a pre-uninstall script
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component jupyter-kernel-gateway'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component jupyter-kernel-gateway'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component jupyter-kernel-gateway
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component jupyter-kernel-gateway
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=jupyter-kernel-gateway
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/jupyter-kernel-gateway.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/jupyter-kernel-gateway.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Component jupyter-kernel-gateway doesn'\''t have a pre-uninstall script'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Component jupyter-kernel-gateway doesn't have a pre-uninstall script
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component kerberos'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component kerberos'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/kerberos.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/kerberos.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/kerberos.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/kerberos.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/kerberos.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/kerberos.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-kerberos
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-kerberos[4531]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + is_rocky
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: ++ os_id
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: ++ cut -d= -f2
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: ++ grep '^ID=' /etc/os-release
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: ++ xargs
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + [[ debian == \r\o\c\k\y ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + mark_packages_to_uninstall krb5-user krb5-config krb5-kdc krb5-admin-server krb5-kpropd xinetd
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/krb5-user
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/krb5-config
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/krb5-kdc
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/krb5-admin-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/krb5-kpropd
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-kerberos[4531]: + touch /tmp/dataproc/uninstall/xinetd
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/kerberos.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component knox'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component knox'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/knox.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/knox.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/knox.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/knox.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/knox.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/knox.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-knox[4606]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/knox.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-knox[4606]: + mark_packages_to_uninstall knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-knox[4606]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-knox[4606]: + touch /tmp/dataproc/uninstall/knox
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component proxy-agent'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component proxy-agent'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component proxy-agent
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component proxy-agent
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=proxy-agent
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/proxy-agent.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/proxy-agent.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Component proxy-agent doesn'\''t have a pre-uninstall script'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Component proxy-agent doesn't have a pre-uninstall script
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component ranger'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component ranger'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/ranger.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/ranger.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/ranger.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/ranger.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/ranger.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/ranger.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-ranger[4671]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/ranger.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-ranger[4671]: + mark_packages_to_uninstall ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-ranger[4671]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-ranger[4671]: + touch /tmp/dataproc/uninstall/ranger
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component rubix'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component rubix'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/rubix.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/rubix.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/rubix.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/rubix.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/rubix.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/rubix.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-rubix[4736]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/rubix.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-rubix[4736]: + mark_packages_to_uninstall rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-rubix[4736]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-rubix[4736]: + touch /tmp/dataproc/uninstall/rubix
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component solr-server'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component solr-server'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/solr-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/solr-server.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/solr-server.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/solr-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/solr-server.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/solr-server.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-solr-server[4801]'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/solr-server.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-solr-server[4801]: + mark_packages_to_uninstall solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-solr-server[4801]: + for package in "$@"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component stackdriver-agent-container'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component stackdriver-agent-container'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component stackdriver-agent-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component stackdriver-agent-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=stackdriver-agent-container
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/stackdriver-agent-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/stackdriver-agent-container.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/stackdriver-agent-container.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/stackdriver-agent-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/stackdriver-agent-container.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: <13>Apr 27 18:07:43 dataproc-pre-uninstall-component-solr-server[4801]: + touch /tmp/dataproc/uninstall/solr-server
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/stackdriver-agent-container.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/stackdriver-agent-container.done
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component trino'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component trino'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Pre-uninstalling component trino
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + pre_uninstall_component trino
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r component=trino
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/trino.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/trino.sh ]]
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/trino.sh'
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/trino.sh
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/trino.running
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:43 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/trino.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-trino
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-trino
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-trino[4869]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/trino.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-trino[4869]: + mark_packages_to_uninstall trino
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-trino[4869]: + for package in "$@"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-trino[4869]: + touch /tmp/dataproc/uninstall/trino
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component zeppelin'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component zeppelin'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Pre-uninstalling component zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + pre_uninstall_component zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r component=zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zeppelin.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zeppelin.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zeppelin.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zeppelin.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/zeppelin.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zeppelin.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-zeppelin[4934]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/zeppelin.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zeppelin[4934]: + mark_packages_to_uninstall zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zeppelin[4934]: + for package in "$@"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zeppelin[4934]: + touch /tmp/dataproc/uninstall/zeppelin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Pre-uninstalling component zookeeper-server'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Pre-uninstalling component zookeeper-server'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Pre-uninstalling component zookeeper-server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + pre_uninstall_component zookeeper-server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r component=zookeeper-server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pre_uninstall_script=/usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zookeeper-server.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zookeeper-server.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zookeeper-server.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Running component pre-uninstall script: /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zookeeper-server.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/zookeeper-server.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + bash -e /usr/local/share/google/dataproc/bdutil/components/pre-uninstall/zookeeper-server.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + set_log_tag pre-uninstall-component-zookeper
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r tag=dataproc-pre-uninstall-component-zookeper
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + exec
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-pre-uninstall-component-zookeper[4999]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + touch /tmp/dataproc/components/pre-uninstall/zookeeper-server.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zookeper[4999]: + mark_packages_to_uninstall zookeeper-server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zookeper[4999]: + for package in "$@"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-pre-uninstall-component-zookeper[4999]: + touch /tmp/dataproc/uninstall/zookeeper-server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Uninstalling packages which must be uninstalled before activating components'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Uninstalling packages which must be uninstalled before activating components'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Uninstalling packages which must be uninstalled before activating components
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + uninstall_packages_pre_activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local packages_to_uninstall
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + packages_to_uninstall=($(list_packages_to_uninstall_pre_activate))
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ list_packages_to_uninstall_pre_activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ find /tmp/dataproc/uninstall-pre-activate/ -type f -exec basename '{}' ';'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 -gt 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Starting to uninstall artifacts'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Starting to uninstall artifacts'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Starting to uninstall artifacts
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + start_uninstall_artifacts
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local blocking_default=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_version_at_least 2.2 2.0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + case ${compare_versions_result} in
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local blocking
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.uninstall.packages.blocking ''
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + blocking=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ -z '' ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local init_action_count
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value attributes/dataproc-initialization-script-count
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + init_action_count=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 == \0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + blocking=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + disable_unattended_upgrades_shutdown
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_rocky
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ os_id
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ cut -d= -f2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag delayed_uninstall_artifacts delayed_uninstall_artifacts
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5021
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-delayed_uninstall_artifacts
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 1 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + delayed_uninstall_artifacts
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ xargs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ grep '^ID=' /etc/os-release
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-delayed_uninstall_artifacts[5021]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-delayed_uninstall_artifacts[5021]: + sleep 60
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ debian == \r\o\c\k\y ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ get_metadata_value scheduling/preemptible
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ FALSE = \T\R\U\E ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.multi.user.metadata.proxy.enabled false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + MULTI_USER_METADATA_PROXY_ENABLED=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + readonly MULTI_USER_METADATA_PROXY_ENABLED
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Starting services'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Starting services'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Starting services
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + start_component_services
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + services=()
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r services
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating components'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating components'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating components
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_components earlyoom fluentbit-ucp hdfs hive-metastore hive-server2 mapreduce miniconda3 mysql npd otel-ucp pig spark tez yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + components=('earlyoom' 'fluentbit-ucp' 'hdfs' 'hive-metastore' 'hive-server2' 'mapreduce' 'miniconda3' 'mysql' 'npd' 'otel-ucp' 'pig' 'spark' 'tez' 'yarn')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local components
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ earlyoom != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: earlyoom'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: earlyoom'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-earlyoom activate_component earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5042
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5042.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-earlyoom activate_component earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component earlyoom'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5042
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component earlyoom] as pid 5042'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component earlyoom] as pid 5042
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ fluentbit-ucp != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: fluentbit-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: fluentbit-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-fluentbit-ucp activate_component fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5044
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-earlyoom[5042]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5044.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component fluentbit-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component fluentbit-ucp] as pid 5044'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component fluentbit-ucp] as pid 5044
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ hdfs != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: hdfs'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: hdfs'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-hdfs activate_component hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5047
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5047.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component hdfs'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component hdfs] as pid 5047'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component hdfs] as pid 5047
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ hive-metastore != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: hive-metastore'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: hive-metastore'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-hive-metastore activate_component hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5048
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5048.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component hive-metastore'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component hive-metastore] as pid 5048'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component hive-metastore] as pid 5048
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ hive-server2 != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: hive-server2'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: hive-server2'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-hive-server2 activate_component hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r component=earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-hdfs activate_component hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5047
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5049
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5049.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component hive-server2'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component hive-server2] as pid 5049'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component hive-server2] as pid 5049
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ mapreduce != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: mapreduce'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: mapreduce'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-mapreduce activate_component mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5052
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5052.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component mapreduce'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component mapreduce] as pid 5052'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component mapreduce] as pid 5052
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ miniconda3 != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: miniconda3'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: miniconda3'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-miniconda3 activate_component miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5053
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5053.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component miniconda3'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component miniconda3] as pid 5053'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component miniconda3] as pid 5053
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ mysql != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: mysql'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: mysql'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-mysql activate_component mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-hdfs[5047]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5055
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5055.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component mysql'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component mysql] as pid 5055'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component mysql] as pid 5055
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-mysql activate_component mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5055
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ npd != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: npd'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: npd'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-npd activate_component npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5058
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5058.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component npd'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component npd] as pid 5058'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component npd] as pid 5058
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ otel-ucp != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: otel-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: otel-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-otel-ucp activate_component otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5060
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5060.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component otel-ucp'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component otel-ucp] as pid 5060'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component otel-ucp] as pid 5060
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ pig != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: pig'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: pig'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-pig activate_component pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5061
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5061.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component pig'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component pig] as pid 5061'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component pig] as pid 5061
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ spark != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: spark'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: spark'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + local -r component=hdfs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + touch /tmp/dataproc/components/activate/hdfs.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-spark activate_component spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-mysql[5055]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5063
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5063.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component spark'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component spark] as pid 5063'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component spark] as pid 5063
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ tez != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: tez'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: tez'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-tez activate_component tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5065
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5065.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component tez'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component tez] as pid 5065'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component tez] as pid 5065
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + for component in "${components[@]}"
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ yarn != \k\e\r\b\e\r\o\s ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Activating: yarn'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Activating: yarn'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Activating: yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag activate-component-yarn activate_component yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5068
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-spark activate_component spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5068.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5063
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'activate_component yarn'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [activate_component yarn] as pid 5068'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [activate_component yarn] as pid 5068
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_hermetic_vm
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r sentinel_file=/etc/google-dataproc/hermetic_vm
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ -f /etc/google-dataproc/hermetic_vm ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local hermetic_vm
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-pig activate_component pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-otel-ucp activate_component otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-npd activate_component npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5060
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-yarn activate_component yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5061
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5058
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r component=mysql
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5068
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + touch /tmp/dataproc/components/activate/mysql.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-spark[5063]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-miniconda3 activate_component miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-yarn[5068]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5053
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-mapreduce activate_component mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5052
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-tez activate_component tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5065
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + local -r start=1745777264.219902504
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hdfs[5047]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-hive-server2 activate_component hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5049
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r component=spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/spark.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + touch /tmp/dataproc/components/activate/spark.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ /usr/share/google/get_metadata_value attributes/hermetic-vm
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-hive-metastore activate_component hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5048
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-npd[5058]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-pig[5061]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-mapreduce[5052]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-otel-ucp[5060]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + touch /tmp/dataproc/components/activate/earlyoom.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-miniconda3[5053]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-tez[5065]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-hive-server2[5049]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r component=yarn
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + touch /tmp/dataproc/components/activate/yarn.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r start=1745777264.233529176
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-hive-metastore[5048]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag activate-component-fluentbit-ucp activate_component fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5044
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-activate-component-fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + activate_component fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r component=otel-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r component=pig
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/pig.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + touch /tmp/dataproc/components/activate/pig.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + touch /tmp/dataproc/components/activate/otel-ucp.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r component=npd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/npd.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + touch /tmp/dataproc/components/activate/npd.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r component=miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r start=1745777264.253026692
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + touch /tmp/dataproc/components/activate/miniconda3.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r component=tez
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/tez.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + touch /tmp/dataproc/components/activate/tez.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r component=mapreduce
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + touch /tmp/dataproc/components/activate/mapreduce.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r component=hive-server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + touch /tmp/dataproc/components/activate/hive-server2.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + local -r component=hive-metastore
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + touch /tmp/dataproc/components/activate/hive-metastore.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-activate-component-fluentbit-ucp[5044]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r start=1745777264.264748013
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r start=1745777264.266037208
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r start=1745777264.266262580
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r start=1745777264.267403354
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r component=fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r activate_script=/usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + [[ -f /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + echo 'Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: Running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + mkdir -p /tmp/dataproc/components/activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + touch /tmp/dataproc/components/activate/fluentbit-ucp.running
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r start=1745777264.267938842
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local exit_code=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r start=1745777264.272369008
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r start=1745777264.271928503
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r end=1745777264.272265778
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + echo 'Component mysql took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: Component mysql took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + local -r time_file=/tmp/dataproc/components/activate/mysql.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + touch /tmp/dataproc/components/activate/mysql.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r start=1745777264.275694068
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r start=1745777264.277071777
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r start=1745777264.283614328
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mysql.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mysql[5055]: + touch /tmp/dataproc/components/activate/mysql.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + local -r start=1745777264.284121898
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: + bash -e /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r end=1745777264.305462454
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + echo 'Component tez took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: Component tez took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + local -r time_file=/tmp/dataproc/components/activate/tez.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + touch /tmp/dataproc/components/activate/tez.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r end=1745777264.318141701
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + echo 'Component pig took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: Component pig took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + local -r time_file=/tmp/dataproc/components/activate/pig.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + touch /tmp/dataproc/components/activate/pig.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/tez.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-tez[5065]: + touch /tmp/dataproc/components/activate/tez.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/pig.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-pig[5061]: + touch /tmp/dataproc/components/activate/pig.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + echo 'Skip running MapReduce history server on Worker node cluster-dip-01-w-2'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: Skip running MapReduce history server on Worker node cluster-dip-01-w-2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r end=1745777264.352489612
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + echo 'Component mapreduce took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: Component mapreduce took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + local -r time_file=/tmp/dataproc/components/activate/mapreduce.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + touch /tmp/dataproc/components/activate/mapreduce.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + main
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r earlyoom_config_file=/etc/default/earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + is_earlyoom_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ Worker == \W\o\r\k\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + get_dataproc_property_or_default internal.node.main.memory-protection-worker.enabled false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/mapreduce.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-mapreduce[5052]: + touch /tmp/dataproc/components/activate/mapreduce.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + is_default_system_metrics_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_dataproc_property dataproc.monitoring.default.metrics.system.enable
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + configure_earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r earlyoom_log_file=/var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r 'prefer_regex=^.*java[[:space:]].*application[_0-9]+[^[:space:]]+container[_0-9]+.*'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local earlyoom_threshold
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ Worker == \W\o\r\k\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ get_dataproc_property_or_default internal.node.main.memory-protection-worker.threshold.kib 65536
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_metadata_master
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r default_metrics_system_enabled=true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + install_effective_python_profile
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ ! -f /etc/profile.d/effective-python.sh ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + generate_effective_python_profile
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ /opt/conda/miniconda3 != \/\o\p\t\/\c\o\n\d\a\/\d\e\f\a\u\l\t ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + ln -f -s /opt/conda/miniconda3 /opt/conda/default
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_dataproc_property dataproc.monitoring.job.yarn.metrics.enable
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + emit_conda_profile /opt/conda/default
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r conda_dir=/opt/conda/default
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r python_bin=/opt/conda/default/bin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local temp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ mktemp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + hermetic_vm=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + return 1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_service_installed google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r service=google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local output
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + (( i = 0 ))
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + (( i < 10 ))
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + temp=/tmp/tmp.hze7QnP3Ku
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + ln -f -s /opt/conda/default/etc/profile.d/conda.sh /etc/profile.d/conda.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + earlyoom_threshold=65536
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + touch /var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ systemctl cat google-osconfig-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + chmod +x /opt/conda/default/etc/profile.d/conda.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_dataproc_property dataproc.metrics.node.yarn.nodemanager.health.enable
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + chmod a+rw /var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + enable_and_start_service earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r service=earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + enable_service earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r service=earlyoom
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r unit=earlyoom.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + retry_constant_short systemctl enable earlyoom.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + retry_constant_custom 30 1 systemctl enable earlyoom.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r max_retry_time=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + cmd=('systemctl' 'enable' 'earlyoom.service')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r max_retries=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: About to run 'systemctl enable earlyoom.service' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + mv -n -v /tmp/tmp.hze7QnP3Ku /etc/profile.d/effective-python.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + output='# /lib/systemd/system/google-osconfig-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: [Unit]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Description=Google OSConfig Agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: After=local-fs.target network-online.target
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Wants=local-fs.target network-online.target
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: [Service]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ExecStart=/usr/bin/google_osconfig_agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Restart=always
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: RestartSec=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: StartLimitInterval=120
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: StartLimitBurst=3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: KillMode=mixed
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: KillSignal=SIGTERM
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: [Install]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: WantedBy=multi-user.target
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: 
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: # /etc/systemd/system/google-osconfig-agent.service.d/dataproc.conf
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: [Unit]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ConditionPathExists=!/etc/google-dataproc/hermetic_vm'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 0 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + return 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + loginfo 'Starting service google-osconfig-agent'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Starting service google-osconfig-agent'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Starting service google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_in_background --tag start-osconfig-service enable_and_start_service google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r pid=5454
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5454.running ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'enable_and_start_service google-osconfig-agent'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + echo 'Started background process [enable_and_start_service google-osconfig-agent] as pid 5454'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: Started background process [enable_and_start_service google-osconfig-agent] as pid 5454
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_syslog_logging_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local syslog_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: Created symlink /etc/systemd/system/multi-user.target.wants/earlyoom.service  /etc/systemd/system/earlyoom.service.
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + run_with_logger --tag start-osconfig-service enable_and_start_service google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local pid=5454
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + tag=dataproc-start-osconfig-service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ 2 -eq 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + enable_and_start_service google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: renamed '/tmp/tmp.hze7QnP3Ku' -> '/etc/profile.d/effective-python.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + chmod a+r /etc/profile.d/effective-python.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ get_dataproc_property_or_default dataproc.logging.syslog.enabled false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + configure_npd true true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r yarn_job_metrics_enabled=true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r yarn_nm_metrics_enabled=true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r init_script=/etc/systemd/system/npd.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r config_dir=/usr/local/share/google/dataproc/npd-config
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs=()
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local npd_configs
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs+=("--stackdriver-config=${config_dir}/exporter/stackdriver-exporter.json")
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs+=("--config.system-stats-monitor=${config_dir}/system-stats-monitor.json,${config_dir}/net-cgroup-system-stats-monitor.json")
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local yarn_job_monitor_config_file=yarn-rm-monitor
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + is_component_selected kerberos
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r component=kerberos
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local activated_components
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + rm -Rf /tmp/tmp.hze7QnP3Ku
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_components_to_activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-start-osconfig-service[5454]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + customize_conda_env /opt/conda/miniconda3 /opt/conda/miniconda3/bin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r conda_install_path=/opt/conda/miniconda3
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r conda_bin_dir=/opt/conda/miniconda3/bin
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: ++ get_dataproc_property dataproc.observability.containerised.legacy.agents.enable
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ get_dataproc_property conda.env.config.uri
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r service=google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + enable_service google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r service=google-osconfig-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r unit=google-osconfig-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_metadata_master_additional
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + retry_constant_short systemctl enable google-osconfig-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + retry_constant_custom 30 1 systemctl enable google-osconfig-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r max_retry_time=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + cmd=('systemctl' 'enable' 'google-osconfig-agent.service')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local -r max_retries=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: About to run 'systemctl enable google-osconfig-agent.service' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + syslog_enabled=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ us-east1 != \g\l\o\b\a\l ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + add_regional_bigtop_repo us-east1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r region=us-east1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r dataproc_repo_file=/etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + is_test_bigtop_repo /etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r dataproc_repo_file=/etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + return '!' grep -q dataproc-bigtop-repo /etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: /usr/local/share/google/dataproc/bdutil/os/shared.sh: line 8: return: !: numeric argument required
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local regional_bigtop_repo_uri
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs+=("--config.yarn-monitor=${config_dir}/${yarn_job_monitor_config_file}.json")
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local yarn_nm_monitor_config_file=yarn-nm-monitor
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local nm_base_url=http://localhost:8042
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + is_component_selected kerberos
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r component=kerberos
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local activated_components
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + CONTAINERISED_AGENTS_ENABLED=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + [[ '' == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + enable_and_start_service otel-metrics-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r service=otel-metrics-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + enable_service otel-metrics-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r service=otel-metrics-agent
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r unit=otel-metrics-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + retry_constant_short systemctl enable otel-metrics-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + retry_constant_custom 30 1 systemctl enable otel-metrics-agent.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r max_retry_time=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + cmd=('systemctl' 'enable' 'otel-metrics-agent.service')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local -r max_retries=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-otel-ucp[5060]: About to run 'systemctl enable otel-metrics-agent.service' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ cat /etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ sed s#dataproc-bigtop-repo#goog-dataproc-bigtop-repo-us-east1#
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ grep 'deb .*goog-dataproc-bigtop-repo-us-east1.* dataproc contrib'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_components_to_activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ tr '[:upper:]' '[:lower:]'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ get_dataproc_property dataproc.components.activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ head -1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r conda_env_config_uri=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ cut -d ' ' -f 2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ get_dataproc_property conda.packages
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r conda_packages=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ get_dataproc_property pip.packages
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + regional_bigtop_repo_uri=https://storage.googleapis.com/goog-dataproc-bigtop-repo-us-east1/2_2_deb12_20250415_125600-RC01
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + [[ https://storage.googleapis.com/goog-dataproc-bigtop-repo-us-east1/2_2_deb12_20250415_125600-RC01 == */ ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + local -r bigtop_key_uri=https://storage.googleapis.com/goog-dataproc-bigtop-repo-us-east1/2_2_deb12_20250415_125600-RC01/archive.key
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + apt-key add -
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: + curl -fsS --retry-connrefused --retry 3 --retry-delay 5 https://storage.googleapis.com/goog-dataproc-bigtop-repo-us-east1/2_2_deb12_20250415_125600-RC01/archive.key
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + activated_components='knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ knox proxy-agent earlyoom hdfs hive-metastore hive-server2 mapreduce mysql npd spark tez yarn pig fluentbit-ucp otel-ucp miniconda3 == *kerberos* ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + sed -i -e s#NM_URL_PLACEHOLDER#http://localhost:8042# /usr/local/share/google/dataproc/npd-config/yarn-nm-monitor.json
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r pip_packages=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ -n '' ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + retry_constant_custom 4 1 install_conda_packages /opt/conda/miniconda3/bin ''
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r max_retry_time=4
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + cmd=('install_conda_packages' '/opt/conda/miniconda3/bin' '')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r max_retries=4
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: About to run 'install_conda_packages /opt/conda/miniconda3/bin ' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: 'install_conda_packages /opt/conda/miniconda3/bin ' succeeded after 1 execution(s).
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + return 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + retry_constant_custom 4 1 install_pip_packages ''
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r max_retry_time=4
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + cmd=('install_pip_packages' '')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r max_retries=4
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: About to run 'install_pip_packages ' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: 'install_pip_packages ' succeeded after 1 execution(s).
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + return 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs+=("--config.yarn-monitor=${config_dir}/${yarn_nm_monitor_config_file}.json")
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + is_earlyoom_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + [[ Worker == \W\o\r\k\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + get_dataproc_property_or_default internal.node.main.memory-protection-worker.enabled false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: ++ get_dataproc_property yarn.atsv2.bigtable.instance
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r end=1745777264.689724013
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + echo 'Component miniconda3 took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: Component miniconda3 took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + local -r time_file=/tmp/dataproc/components/activate/miniconda3.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + touch /tmp/dataproc/components/activate/miniconda3.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + readonly WAIT_TIMEOUT_SECONDS=200
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + WAIT_TIMEOUT_SECONDS=200
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + readonly INITIAL_WORKER_COUNT=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + INITIAL_WORKER_COUNT=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ get_metadata_master
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ get_dataproc_property_or_default dataproc:componentgateway.ha.enabled false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ NUM_MASTERS=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_metadata_role
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: true
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r earlyoom_log_file=/var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + touch /var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/miniconda3.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-miniconda3[5053]: + touch /tmp/dataproc/components/activate/miniconda3.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + chmod a+rw /var/log/earlyoom.log
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + readonly ATSV2_BIGTABLE_RESOURCE=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + ATSV2_BIGTABLE_RESOURCE=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + [[ -n '' ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + npd_configs+=("--config.system-log-monitor=${config_dir}/earlyoom-monitor.json")
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + create_systemd_service /etc/systemd/system/npd.service '--stackdriver-config=/usr/local/share/google/dataproc/npd-config/exporter/stackdriver-exporter.json --config.system-stats-monitor=/usr/local/share/google/dataproc/npd-config/system-stats-monitor.json,/usr/local/share/google/dataproc/npd-config/net-cgroup-system-stats-monitor.json --config.yarn-monitor=/usr/local/share/google/dataproc/npd-config/yarn-rm-monitor.json --config.yarn-monitor=/usr/local/share/google/dataproc/npd-config/yarn-nm-monitor.json --config.system-log-monitor=/usr/local/share/google/dataproc/npd-config/earlyoom-monitor.json'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r service_path=/etc/systemd/system/npd.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + local -r 'npd_config_args=--stackdriver-config=/usr/local/share/google/dataproc/npd-config/exporter/stackdriver-exporter.json --config.system-stats-monitor=/usr/local/share/google/dataproc/npd-config/system-stats-monitor.json,/usr/local/share/google/dataproc/npd-config/net-cgroup-system-stats-monitor.json --config.yarn-monitor=/usr/local/share/google/dataproc/npd-config/yarn-rm-monitor.json --config.yarn-monitor=/usr/local/share/google/dataproc/npd-config/yarn-nm-monitor.json --config.system-log-monitor=/usr/local/share/google/dataproc/npd-config/earlyoom-monitor.json'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r end=1745777264.757253415
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + echo 'Component yarn took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: Component yarn took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + local -r time_file=/tmp/dataproc/components/activate/yarn.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + touch /tmp/dataproc/components/activate/yarn.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-npd[5058]: + systemctl daemon-reload
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: 'systemctl enable earlyoom.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-start-osconfig-service[5454]: Created symlink /etc/systemd/system/multi-user.target.wants/google-osconfig-agent.service  /lib/systemd/system/google-osconfig-agent.service.
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + return 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local -r drop_in_dir=/etc/systemd/system/earlyoom.service.d
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + mkdir -p /etc/systemd/system/earlyoom.service.d
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + COMPONENT_GATEWAY_HA_ENABLED=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + readonly COMPONENT_GATEWAY_HA_ENABLED
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + activate_spark
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ standard == \s\e\r\v\e\r\l\e\s\s\-\s\p\a\r\k ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + should_start_history_server
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + should_start_spark_connect
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local role
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: + local props
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ retry_constant_short systemctl show earlyoom.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ retry_constant_custom 30 1 systemctl show earlyoom.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ cmd=('systemctl' 'show' 'earlyoom.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ local -r max_retries=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-earlyoom[5042]: About to run 'systemctl show earlyoom.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ get_metadata_role
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/yarn.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-yarn[5068]: + touch /tmp/dataproc/components/activate/yarn.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: ++ get_dataproc_property dataproc.logging.stackdriver.enable
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + STACKDRIVER_LOGGING_ENABLED=
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + [[ '' == \f\a\l\s\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + is_legacy_containerized_agents_enabled
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: ++ get_dataproc_property_or_default dataproc.observability.containerised.legacy.agents.enable false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: ++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: +++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ get_metadata_master_additional
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-metastore[5048]: ++++ set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ ROLE=Worker
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ [[ 1 -gt 1 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: +++ CLUSTER_MASTER_METASTORE_URIS=thrift://cluster-dip-01-m:9083
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++ HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + set -x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + activate_hive_server2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + echo 'Skip running Hive server on Worker node cluster-dip-01-w-2'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: Skip running Hive server on Worker node cluster-dip-01-w-2
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r legacy_containerised_agents_enabled=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + [[ false == \t\r\u\e ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + enable_and_start_service fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r service=fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + enable_service fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r service=fluentbit-ucp
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r unit=fluentbit-ucp.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + retry_constant_short systemctl enable fluentbit-ucp.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + retry_constant_custom 30 1 systemctl enable fluentbit-ucp.service
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r max_retry_time=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r retry_delay=1
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + cmd=('systemctl' 'enable' 'fluentbit-ucp.service')
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r cmd
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local -r max_retries=30
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + local reenable_x=false
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + [[ -o xtrace ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: + set +x
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-fluentbit-ucp[5044]: About to run 'systemctl enable fluentbit-ucp.service' with retries...
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + role=Worker
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: ++ date +%s.%N
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r end=1745777264.942415956
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + echo 'Component hive-server2 took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: Component hive-server2 took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + local -r time_file=/tmp/dataproc/components/activate/hive-server2.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + touch /tmp/dataproc/components/activate/hive-server2.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-server2.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-hive-server2[5049]: + touch /tmp/dataproc/components/activate/hive-server2.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r end=1745777264.949126830
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r runtime_s=0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + echo 'Component spark took 0s to activate'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: Component spark took 0s to activate
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + local -r time_file=/tmp/dataproc/components/activate/spark.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + touch /tmp/dataproc/components/activate/spark.time
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + cat
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh'
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/spark.sh
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: <13>Apr 27 18:07:44 dataproc-activate-component-spark[5063]: + touch /tmp/dataproc/components/activate/spark.done
<13>Apr 27 18:07:44 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ NUM_MASTERS=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++++ get_metadata_role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: 'systemctl enable google-osconfig-agent.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r drop_in_dir=/etc/systemd/system/google-osconfig-agent.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + mkdir -p /etc/systemd/system/google-osconfig-agent.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local props
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ retry_constant_short systemctl show google-osconfig-agent.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ retry_constant_custom 30 1 systemctl show google-osconfig-agent.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ cmd=('systemctl' 'show' 'google-osconfig-agent.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: About to run 'systemctl show google-osconfig-agent.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ ROLE=Worker
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ [[ 1 -gt 1 ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ CLUSTER_MASTER_METASTORE_URIS=thrift://cluster-dip-01-m:9083
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ dirname /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + source /usr/local/share/google/dataproc/bdutil/components/activate/../shared/hive-metastore.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set -euo pipefail
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ dirname /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ source /usr/local/share/google/dataproc/bdutil/components/activate/../../bdutil_metadata.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set -x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_metadata_master
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_metadata_master_additional
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_dataproc_metadata DATAPROC_METADATA_MASTER_ADDITIONAL attributes/dataproc-master-additional
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + MASTER_HOSTNAMES=(${DATAPROC_MASTER} ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ DATAPROC_MASTER_ADDITIONAL=
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ MASTER_HOSTNAMES=($DATAPROC_MASTER ${DATAPROC_MASTER_ADDITIONAL//,/ })
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ NUM_MASTERS=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ get_metadata_cluster_name
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ get_dataproc_metadata DATAPROC_METADATA_CLUSTER_NAME attributes/dataproc-cluster-name
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_metadata_role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: +++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + CLUSTER_NAME=cluster-dip-01
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + activate_hdfs
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + mkdir -p /var/run/hadoop-hdfs
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + sudo -u hdfs hdfs namenode -genclusterid
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + chown root:hdfs /var/run/hadoop-hdfs
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ ROLE=Worker
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ [[ 1 -gt 1 ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ CLUSTER_MASTER_METASTORE_URIS=thrift://cluster-dip-01-m:9083
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ dirname /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + chmod 775 /var/run/hadoop-hdfs
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + source /usr/local/share/google/dataproc/bdutil/components/activate/../shared/mysql.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ source /usr/local/share/google/dataproc/bdutil/bdutil_versions.sh
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ is_version_at_least 2.2 2.2
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ case ${compare_versions_result} in
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ MYSQL_VERSION=8.0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ MYSQL_EL_VERSION=8
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + set -x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + enable_worker_services
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_metadata_role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_dataproc_metadata DATAPROC_METADATA_ROLE attributes/dataproc-role
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ get_metadata_datanode_enabled
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ get_dataproc_metadata DATAPROC_METADATA_DATANODE_ENABLED attributes/dataproc-datanode-enabled
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + enable_and_start_service npd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r service=npd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + enable_service npd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r service=npd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r unit=npd.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + retry_constant_short systemctl enable npd.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + retry_constant_custom 30 1 systemctl enable npd.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + cmd=('systemctl' 'enable' 'npd.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: + set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: About to run 'systemctl enable npd.service' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: 'systemctl show earlyoom.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: ++ return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + props='Restart=always
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: RemainAfterExit=no'
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ earlyoom != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ earlyoom != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ Restart=always
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: RemainAfterExit=no == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ earlyoom == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ earlyoom == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + start_service earlyoom
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + start_services earlyoom
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + units=('earlyoom.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r units
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + retry_constant_short systemctl start earlyoom.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + retry_constant_custom 30 1 systemctl start earlyoom.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + cmd=('systemctl' 'start' 'earlyoom.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: + set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-earlyoom[5042]: About to run 'systemctl start earlyoom.service' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r datanode_enabled=true
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + ROLE=Worker
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + [[ true == \t\r\u\e ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + enable_service hadoop-hdfs-datanode
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_metadata_master
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r service=hadoop-hdfs-datanode
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_dataproc_metadata DATAPROC_METADATA_MASTER attributes/dataproc-master
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r unit=hadoop-hdfs-datanode.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + retry_constant_short systemctl enable hadoop-hdfs-datanode.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + retry_constant_custom 30 1 systemctl enable hadoop-hdfs-datanode.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + cmd=('systemctl' 'enable' 'hadoop-hdfs-datanode.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: + set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: About to run 'systemctl enable hadoop-hdfs-datanode.service' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: hadoop-hdfs-datanode.service is not a native service, redirecting to systemd-sysv-install.
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hdfs[5047]: Executing: /lib/systemd/systemd-sysv-install enable hadoop-hdfs-datanode
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + DATAPROC_MASTER=cluster-dip-01-m
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_metadata_bucket
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ get_dataproc_metadata DATAPROC_METADATA_BUCKET attributes/dataproc-bucket
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + CONFIGBUCKET=dataproc-staging-us-east1-679657336577-kutp8kah
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + HIVE_STAGING_LOCATION=gs://dataproc-staging-us-east1-679657336577-kutp8kah/google-cloud-dataproc-metainfo/0b63cfa9-1f8a-481e-87c8-a0cf661f3625/hive
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: 'systemctl enable otel-metrics-agent.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: + return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: + local -r drop_in_dir=/etc/systemd/system/otel-metrics-agent.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: + mkdir -p /etc/systemd/system/otel-metrics-agent.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: + local props
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ retry_constant_short systemctl show otel-metrics-agent.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ retry_constant_custom 30 1 systemctl show otel-metrics-agent.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ cmd=('systemctl' 'show' 'otel-metrics-agent.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-otel-ucp[5060]: About to run 'systemctl show otel-metrics-agent.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + activate_hive_metastore
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + [[ Worker == \M\a\s\t\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: ++ hostname
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + echo 'Hive connection password updated for cluster-dip-01-w-2'
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: Hive connection password updated for cluster-dip-01-w-2
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + remove_hive_password_from_workers
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + [[ hive_def_pass_x123 == \h\i\v\e\_\d\e\f\_\p\a\s\s\_\x\1\2\3 ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-hive-metastore[5048]: + bdconfig set_property --configuration_file /etc/hive/conf/hive-site.xml --name javax.jdo.option.ConnectionPassword --value ' ' --clobber
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: 'systemctl enable fluentbit-ucp.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: + return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: + local -r drop_in_dir=/etc/systemd/system/fluentbit-ucp.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: + mkdir -p /etc/systemd/system/fluentbit-ucp.service.d
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: 'systemctl show google-osconfig-agent.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: ++ return 0
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + props='Restart=always
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: RemainAfterExit=no'
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ google-osconfig-agent != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ google-osconfig-agent != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ Restart=always
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: RemainAfterExit=no == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ google-osconfig-agent == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ google-osconfig-agent == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + start_service google-osconfig-agent
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + start_services google-osconfig-agent
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + units=('google-osconfig-agent.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r units
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + retry_constant_short systemctl start google-osconfig-agent.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + retry_constant_custom 30 1 systemctl start google-osconfig-agent.service
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + cmd=('systemctl' 'start' 'google-osconfig-agent.service')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-npd[5058]: Created symlink /etc/systemd/system/multi-user.target.wants/npd.service  /etc/systemd/system/npd.service.
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: + set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-start-osconfig-service[5454]: About to run 'systemctl start google-osconfig-agent.service' with retries...
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: + local props
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ retry_constant_short systemctl show fluentbit-ucp.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ retry_constant_custom 30 1 systemctl show fluentbit-ucp.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ local -r retry_delay=1
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ cmd=('systemctl' 'show' 'fluentbit-ucp.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ local -r cmd
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ local -r max_retries=30
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ local reenable_x=false
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: ++ set +x
<13>Apr 27 18:07:45 dataproc-startup-script[1253]: <13>Apr 27 18:07:45 dataproc-activate-component-fluentbit-ucp[5044]: About to run 'systemctl show fluentbit-ucp.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + local -r end=1745777266.107350866
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + echo 'Component hive-metastore took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: Component hive-metastore took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + local -r time_file=/tmp/dataproc/components/activate/hive-metastore.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + touch /tmp/dataproc/components/activate/hive-metastore.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hive-metastore.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hive-metastore[5048]: + touch /tmp/dataproc/components/activate/hive-metastore.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: 'systemctl enable npd.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r drop_in_dir=/etc/systemd/system/npd.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + mkdir -p /etc/systemd/system/npd.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local props
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ retry_constant_short systemctl show npd.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ retry_constant_custom 30 1 systemctl show npd.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ local -r retry_delay=1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ cmd=('systemctl' 'show' 'npd.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ local -r cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ local -r max_retries=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ local reenable_x=false
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: About to run 'systemctl show npd.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: 'systemctl show otel-metrics-agent.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: ++ return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + props='Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: RemainAfterExit=no'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ otel-metrics-agent != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ otel-metrics-agent != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: RemainAfterExit=no == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ otel-metrics-agent == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ otel-metrics-agent == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + start_service otel-metrics-agent
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + start_services otel-metrics-agent
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + units=('otel-metrics-agent.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r units
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + retry_constant_short systemctl start otel-metrics-agent.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + retry_constant_custom 30 1 systemctl start otel-metrics-agent.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r max_retry_time=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r retry_delay=1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + cmd=('systemctl' 'start' 'otel-metrics-agent.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r max_retries=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local reenable_x=false
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ -o xtrace ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: About to run 'systemctl start otel-metrics-agent.service' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: 'systemctl show fluentbit-ucp.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: ++ return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + props='Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: RemainAfterExit=no'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ fluentbit-ucp != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ fluentbit-ucp != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: RemainAfterExit=no == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ fluentbit-ucp == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ fluentbit-ucp == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + start_service fluentbit-ucp
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + start_services fluentbit-ucp
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + units=('fluentbit-ucp.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r units
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + retry_constant_short systemctl start fluentbit-ucp.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + retry_constant_custom 30 1 systemctl start fluentbit-ucp.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r max_retry_time=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r retry_delay=1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + cmd=('systemctl' 'start' 'fluentbit-ucp.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r max_retries=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local reenable_x=false
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ -o xtrace ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: About to run 'systemctl start fluentbit-ucp.service' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: OK
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo 'Adding regional Bigtop repo for us-east1 in APT sources.'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: Adding regional Bigtop repo for us-east1 in APT sources.
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + cat /etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + mv -f /tmp/dataproc.list /etc/apt/sources.list.d/dataproc.list
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ standard == \s\t\a\n\d\a\r\d ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + run_in_background --tag backup-original-configs backup_original_configs
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local -r pid=6304
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/6304.running ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo backup_original_configs
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo 'Started background process [backup_original_configs] as pid 6304'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: Started background process [backup_original_configs] as pid 6304
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + wait_on_async_processes
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + loginfo 'Waiting on async processes'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo 'Waiting on async processes'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: Waiting on async processes
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local running_file
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + trap 'echo "$?" >"${COMMANDS_TMP_DIR}/${BASHPID}.exitcode"' EXIT
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + run_with_logger --tag backup-original-configs backup_original_configs
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local tag=dataproc-script
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local pid=6304
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ --tag == \-\-\t\a\g ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + tag=dataproc-backup-original-configs
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + shift 2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ 1 -eq 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + backup_original_configs
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5042
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ logger -s -t 'dataproc-backup-original-configs[6304]'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + local -r HIVE_CONF_DIR=/etc/hive/conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + local -r TEZ_CONF_DIR=/etc/tez/conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + mkdir -p /usr/local/share/google/dataproc/conf/original
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hadoop/conf/yarn-site.xml /usr/local/share/google/dataproc/conf/original/original-yarn-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hadoop/conf/hdfs-site.xml /usr/local/share/google/dataproc/conf/original/original-hdfs-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + pid=5042
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + cmd='activate_component earlyoom'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5042 cmd=[activate_component earlyoom]'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo 'Waiting on pid=5042 cmd=[activate_component earlyoom]'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: Waiting on pid=5042 cmd=[activate_component earlyoom]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + echo 'activate_component earlyoom'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5042.exitcode
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5042.exitcode ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: + sleep 1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hadoop/conf/core-site.xml /usr/local/share/google/dataproc/conf/original/original-core-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hadoop/conf/mapred-site.xml /usr/local/share/google/dataproc/conf/original/original-mapred-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hadoop/conf/capacity-scheduler.xml /usr/local/share/google/dataproc/conf/original/original-capacity-scheduler.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/hive/conf/hive-site.xml /usr/local/share/google/dataproc/conf/original/original-hive-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/tez/conf/tez-site.xml /usr/local/share/google/dataproc/conf/original/original-tez-site.xml
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-backup-original-configs[6304]: + cp /etc/spark/conf/spark-defaults.conf /usr/local/share/google/dataproc/conf/original/original-spark-defaults.conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: 'systemctl show npd.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + props='Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: RemainAfterExit=no'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ npd != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ npd != \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ Restart=on-failure
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: RemainAfterExit=no == *\R\e\s\t\a\r\t\=\n\o* ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ npd == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ npd == \h\a\d\o\o\p\-\y\a\r\n\-\n\o\d\e\m\a\n\a\g\e\r ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + start_service npd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + start_services npd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + units=('npd.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r units
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + retry_constant_short systemctl start npd.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + retry_constant_custom 30 1 systemctl start npd.service
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r max_retry_time=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r retry_delay=1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + cmd=('systemctl' 'start' 'npd.service')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r max_retries=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local reenable_x=false
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ -o xtrace ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: About to run 'systemctl start npd.service' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: 'systemctl enable hadoop-hdfs-datanode.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r drop_in_dir=/etc/systemd/system/hadoop-hdfs-datanode.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + mkdir -p /etc/systemd/system/hadoop-hdfs-datanode.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local props
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ retry_constant_short systemctl show hadoop-hdfs-datanode.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ retry_constant_custom 30 1 systemctl show hadoop-hdfs-datanode.service -p Restart,RemainAfterExit
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ local -r max_retry_time=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ local -r retry_delay=1
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ cmd=('systemctl' 'show' 'hadoop-hdfs-datanode.service' '-p' 'Restart,RemainAfterExit')
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ local -r cmd
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ local -r max_retries=30
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ local reenable_x=false
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ [[ -o xtrace ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: About to run 'systemctl show hadoop-hdfs-datanode.service -p Restart,RemainAfterExit' with retries...
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: 'systemctl show hadoop-hdfs-datanode.service -p Restart,RemainAfterExit' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + props='Restart=no
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: RemainAfterExit=no'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + [[ hadoop-hdfs-datanode != \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r gate_start_on_agent_success_drop_in=/etc/systemd/system/common/agent-gate.conf
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + [[ ! -f /etc/systemd/system/common/agent-gate.conf ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + [[ hadoop-hdfs-datanode == \h\a\d\o\o\p\-\h\d\f\s\-\d\a\t\a\n\o\d\e ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ get_metadata_worker_count
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ get_dataproc_metadata DATAPROC_METADATA_WORKER_COUNT attributes/dataproc-worker-count
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ set +x
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: 'systemctl start fluentbit-ucp.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: 'systemctl start earlyoom.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: 'systemctl start otel-metrics-agent.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: 'systemctl start npd.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-start-osconfig-service[5454]: 'systemctl start google-osconfig-agent.service' succeeded after 1 execution(s).
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + local -r end=1745777266.707231467
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-start-osconfig-service[5454]: + return 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + echo 'Component earlyoom took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: Component earlyoom took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + local -r time_file=/tmp/dataproc/components/activate/earlyoom.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + touch /tmp/dataproc/components/activate/earlyoom.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/earlyoom.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-earlyoom[5042]: + touch /tmp/dataproc/components/activate/earlyoom.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r end=1745777266.720209103
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + echo 'Component fluentbit-ucp took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: Component fluentbit-ucp took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + local -r time_file=/tmp/dataproc/components/activate/fluentbit-ucp.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + touch /tmp/dataproc/components/activate/fluentbit-ucp.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r worker_count=3
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + [[ 3 != 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + ln -s -f /etc/systemd/system/common/agent-gate.conf /etc/systemd/system/hadoop-hdfs-datanode.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r end=1745777266.727140907
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + echo 'Component npd took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: Component npd took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + local -r time_file=/tmp/dataproc/components/activate/npd.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + touch /tmp/dataproc/components/activate/npd.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r end=1745777266.726840357
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + echo 'Component otel-ucp took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: Component otel-ucp took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + local -r time_file=/tmp/dataproc/components/activate/otel-ucp.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + touch /tmp/dataproc/components/activate/otel-ucp.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/fluentbit-ucp.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-fluentbit-ucp[5044]: + touch /tmp/dataproc/components/activate/fluentbit-ucp.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + ln -s -f /etc/systemd/system/common/worker-restart.conf /etc/systemd/system/hadoop-hdfs-datanode.service.d
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/otel-ucp.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-otel-ucp[5060]: + touch /tmp/dataproc/components/activate/otel-ucp.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/npd.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-npd[5058]: + touch /tmp/dataproc/components/activate/npd.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: ++ date +%s.%N
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r end=1745777266.747758932
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r runtime_s=2
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + echo 'Component hdfs took 2s to activate'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: Component hdfs took 2s to activate
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + local -r time_file=/tmp/dataproc/components/activate/hdfs.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + touch /tmp/dataproc/components/activate/hdfs.time
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + cat
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + [[ 0 -ne 0 ]]
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + echo 'Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh'
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: Done running component activation script: /usr/local/share/google/dataproc/bdutil/components/activate/hdfs.sh
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: <13>Apr 27 18:07:46 dataproc-activate-component-hdfs[5047]: + touch /tmp/dataproc/components/activate/hdfs.done
<13>Apr 27 18:07:46 dataproc-startup-script[1253]: ++ echo 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5042.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5042.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component earlyoom] pid=5042 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component earlyoom] pid=5042 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5042.exitcode /tmp/dataproc/commands/5042.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5044
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5044
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component fluentbit-ucp'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5044 cmd=[activate_component fluentbit-ucp]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5044 cmd=[activate_component fluentbit-ucp]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5044 cmd=[activate_component fluentbit-ucp]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component fluentbit-ucp'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5044.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5044.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5044.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component fluentbit-ucp] pid=5044 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component fluentbit-ucp] pid=5044 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5044.exitcode /tmp/dataproc/commands/5044.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5047
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5047
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component hdfs'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5047 cmd=[activate_component hdfs]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5047 cmd=[activate_component hdfs]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5047 cmd=[activate_component hdfs]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component hdfs'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5047.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5047.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component hdfs] pid=5047 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5047.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component hdfs] pid=5047 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5047.exitcode /tmp/dataproc/commands/5047.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5048
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5048
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component hive-metastore'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5048 cmd=[activate_component hive-metastore]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5048 cmd=[activate_component hive-metastore]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5048 cmd=[activate_component hive-metastore]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component hive-metastore'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5048.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5048.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5048.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component hive-metastore] pid=5048 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component hive-metastore] pid=5048 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5048.exitcode /tmp/dataproc/commands/5048.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5049
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5049
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component hive-server2'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5049 cmd=[activate_component hive-server2]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5049 cmd=[activate_component hive-server2]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5049 cmd=[activate_component hive-server2]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component hive-server2'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5049.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5049.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5049.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component hive-server2] pid=5049 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component hive-server2] pid=5049 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5049.exitcode /tmp/dataproc/commands/5049.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5052
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5052
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component mapreduce'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5052 cmd=[activate_component mapreduce]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5052 cmd=[activate_component mapreduce]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5052 cmd=[activate_component mapreduce]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component mapreduce'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5052.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5052.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component mapreduce] pid=5052 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5052.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component mapreduce] pid=5052 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5052.exitcode /tmp/dataproc/commands/5052.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5053
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5053
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component miniconda3'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5053 cmd=[activate_component miniconda3]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5053 cmd=[activate_component miniconda3]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5053 cmd=[activate_component miniconda3]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component miniconda3'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5053.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5053.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component miniconda3] pid=5053 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5053.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component miniconda3] pid=5053 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5053.exitcode /tmp/dataproc/commands/5053.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5055
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5055
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component mysql'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5055 cmd=[activate_component mysql]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5055 cmd=[activate_component mysql]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5055 cmd=[activate_component mysql]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component mysql'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5055.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5055.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5055.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component mysql] pid=5055 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component mysql] pid=5055 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5055.exitcode /tmp/dataproc/commands/5055.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5058
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5058
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component npd'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5058 cmd=[activate_component npd]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5058 cmd=[activate_component npd]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5058 cmd=[activate_component npd]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component npd'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5058.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5058.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component npd] pid=5058 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5058.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component npd] pid=5058 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5058.exitcode /tmp/dataproc/commands/5058.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5060
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5060
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component otel-ucp'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5060 cmd=[activate_component otel-ucp]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5060 cmd=[activate_component otel-ucp]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5060 cmd=[activate_component otel-ucp]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component otel-ucp'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5060.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5060.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5060.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component otel-ucp] pid=5060 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component otel-ucp] pid=5060 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5060.exitcode /tmp/dataproc/commands/5060.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5061
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5061
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component pig'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5061 cmd=[activate_component pig]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5061 cmd=[activate_component pig]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5061 cmd=[activate_component pig]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component pig'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5061.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5061.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component pig] pid=5061 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5061.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component pig] pid=5061 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5061.exitcode /tmp/dataproc/commands/5061.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5063
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5063
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component spark'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5063 cmd=[activate_component spark]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5063 cmd=[activate_component spark]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5063 cmd=[activate_component spark]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component spark'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5063.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5063.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component spark] pid=5063 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5063.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component spark] pid=5063 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5063.exitcode /tmp/dataproc/commands/5063.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5065
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5065
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component tez'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5065 cmd=[activate_component tez]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5065 cmd=[activate_component tez]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5065 cmd=[activate_component tez]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component tez'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5065.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5065.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component tez] pid=5065 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5065.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component tez] pid=5065 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5065.exitcode /tmp/dataproc/commands/5065.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5068
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5068
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='activate_component yarn'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5068 cmd=[activate_component yarn]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5068 cmd=[activate_component yarn]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5068 cmd=[activate_component yarn]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'activate_component yarn'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5068.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5068.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5068.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[activate_component yarn] pid=5068 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[activate_component yarn] pid=5068 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5068.exitcode /tmp/dataproc/commands/5068.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/5454
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=5454
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd='enable_and_start_service google-osconfig-agent'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=5454 cmd=[enable_and_start_service google-osconfig-agent]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=5454 cmd=[enable_and_start_service google-osconfig-agent]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=5454 cmd=[enable_and_start_service google-osconfig-agent]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'enable_and_start_service google-osconfig-agent'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/5454.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/5454.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/5454.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[enable_and_start_service google-osconfig-agent] pid=5454 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[enable_and_start_service google-osconfig-agent] pid=5454 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/5454.exitcode /tmp/dataproc/commands/5454.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + for running_file in "${COMMANDS_TMP_DIR}/"*'.running'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local pid
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ basename /tmp/dataproc/commands/6304
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + pid=6304
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local cmd
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + cmd=backup_original_configs
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'Waiting on pid=6304 cmd=[backup_original_configs]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Waiting on pid=6304 cmd=[backup_original_configs]'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Waiting on pid=6304 cmd=[backup_original_configs]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo backup_original_configs
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local exitcode_file=/tmp/dataproc/commands/6304.exitcode
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ ! -f /tmp/dataproc/commands/6304.exitcode ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + local status
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + status=0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + (( status != 0 ))
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + tee /tmp/dataproc/commands/6304.done
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'Command cmd=[backup_original_configs] pid=6304 exited with 0'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: Command cmd=[backup_original_configs] pid=6304 exited with 0
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + rm /tmp/dataproc/commands/6304.exitcode /tmp/dataproc/commands/6304.running
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + is_ubuntu
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ os_id
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ cut -d= -f2
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ grep '^ID=' /etc/os-release
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: ++ xargs
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + [[ debian == \u\b\u\n\t\u ]]
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + loginfo 'All done'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: + echo 'All done'
<13>Apr 27 18:07:47 dataproc-startup-script[1253]: All done
